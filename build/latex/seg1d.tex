%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsable pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}



\title{seg1d}
\date{Aug 13, 2021}
\release{0.1.2}
\author{Mathew Schwartz}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}



\chapter{Contents}
\label{\detokenize{index:contents}}

\section{Installation}
\label{\detokenize{install:installation}}\label{\detokenize{install::doc}}

\subsection{Check dependencies}
\label{\detokenize{install:check-dependencies}}
\sphinxAtStartPar
Currently tested on \sphinxcode{\sphinxupquote{Python 3.8+}}.

\sphinxAtStartPar
For the package: \sphinxcode{\sphinxupquote{numpy\textgreater{}=1.15}}, \sphinxcode{\sphinxupquote{scipy\textgreater{}=1.0.0}}, \sphinxcode{\sphinxupquote{sklearn\textgreater{}=0.2}}, \sphinxcode{\sphinxupquote{numba\textgreater{}=0.40}}

\sphinxAtStartPar
For building documentation: \sphinxcode{\sphinxupquote{sphinx}}, \sphinxcode{\sphinxupquote{scipy}} html\_theme, \sphinxcode{\sphinxupquote{numpydoc}}, \sphinxcode{\sphinxupquote{matplotlib}}


\subsection{Get seg1d}
\label{\detokenize{install:get-seg1d}}
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{pip install seg1d}}


\subsection{Building Documentation}
\label{\detokenize{install:building-documentation}}
\sphinxAtStartPar
Documentation is built using sphinx with the scipy html\_theme in the \sphinxcode{\sphinxupquote{docs}} folder.

\sphinxAtStartPar
To get the requirements for building documentation you can run:

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{pip install sphinx numpydoc matplotlib}}

\sphinxAtStartPar
If you have not installed \sphinxcode{\sphinxupquote{seg1d}} you can then run the following to get the remaining requirements

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{pip install numpy scipy sklearn numba}}

\sphinxAtStartPar
Finally, the following two lines will build the documentation.

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{make clean}}

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{make html}}


\subsection{Testing}
\label{\detokenize{install:testing}}
\sphinxAtStartPar
Docstrings examples should be compliant with \sphinxcode{\sphinxupquote{doctest}}.
Navigate to the \sphinxcode{\sphinxupquote{docs}} folder and run:

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{make doctest}}

\sphinxAtStartPar
A summary report will be generated and should not have any failed conditions.
Note, this should be done after building the documentation with \sphinxcode{\sphinxupquote{make html}}.

\sphinxAtStartPar
End\sphinxhyphen{}users can test the installation with a similar method provided through the
examples.

\sphinxAtStartPar
After installation, start a python interactive console and import:

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{from seg1d.examples import test}}

\sphinxAtStartPar
Then run the tests with:

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{test.run()}}

\sphinxAtStartPar
A series of tests will be performed to check for intended output.
While \sphinxcode{\sphinxupquote{matplotlib}} is not a required dependency, if it is not installed, some
of the tests will fail. This will be obvious as the test will show in the
traceback that it failed due to \sphinxcode{\sphinxupquote{No module named \textquotesingle{}matplotlib\textquotesingle{}}}.

\sphinxAtStartPar
Due to variations in OS, many of the doctests use \sphinxcode{\sphinxupquote{np.around}} to ensure matching.
However, sorting of correlation values is dependent on a few platform variables,
so tests that output multiple array values that are identical may show as failed.
The documentation is always tested on Windows 10, Python 3.8 for ensuring compliance.


\section{Getting Started}
\label{\detokenize{start:getting-started}}\label{\detokenize{start::doc}}
\sphinxAtStartPar
In this section, a few simple examples are given to ensure the installation is working
and you are able to segment data.  These examples call a method provided that uses
default parameters for the algorithms within the segmentation process but allows
user input for the data related parameters such as scaling and step size for the
matching process.


\subsection{Sample Data}
\label{\detokenize{start:sample-data}}
\sphinxAtStartPar
A basic example of checking the installation using the included sample data.

\phantomsection\label{\detokenize{start:module-seg1d.examples.ex_simple}}\index{module@\spxentry{module}!seg1d.examples.ex\_simple@\spxentry{seg1d.examples.ex\_simple}}\index{seg1d.examples.ex\_simple@\spxentry{seg1d.examples.ex\_simple}!module@\spxentry{module}}
\sphinxAtStartPar
Example using included sample data

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}retrieve the sample reference, target, and weight data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{r}\PYG{p}{,}\PYG{n}{t}\PYG{p}{,}\PYG{n}{w} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{sampleData}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} define some test parameters}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{minW} \PYG{o}{=} \PYG{l+m+mi}{70} \PYG{c+c1}{\PYGZsh{}minimum percent to scale down reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{maxW} \PYG{o}{=} \PYG{l+m+mi}{150} \PYG{c+c1}{\PYGZsh{}maximum percent to scale up reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{step} \PYG{o}{=} \PYG{l+m+mi}{1} \PYG{c+c1}{\PYGZsh{}step to use for correlating reference to target data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}call the segmentation algorithm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{segment\PYGZus{}data}\PYG{p}{(}\PYG{n}{r}\PYG{p}{,}\PYG{n}{t}\PYG{p}{,}\PYG{n}{w}\PYG{p}{,}\PYG{n}{minW}\PYG{p}{,}\PYG{n}{maxW}\PYG{p}{,}\PYG{n}{step}\PYG{p}{)} \PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7} \PYG{p}{)}
\PYG{g+go}{array([[207.       , 240.       ,   0.9124224],}
\PYG{g+go}{       [342.       , 381.       ,   0.8801901],}
\PYG{g+go}{       [ 72.       , 112.       ,   0.8776795]])}
\end{sphinxVerbatim}


\subsection{Sine Wave}
\label{\detokenize{start:module-seg1d.examples.ex_sine}}\label{\detokenize{start:sine-wave}}\index{module@\spxentry{module}!seg1d.examples.ex\_sine@\spxentry{seg1d.examples.ex\_sine}}\index{seg1d.examples.ex\_sine@\spxentry{seg1d.examples.ex\_sine}!module@\spxentry{module}}
\sphinxAtStartPar
Sample using sine wave

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pylab} \PYG{k}{as} \PYG{n+nn}{plt}
\end{sphinxVerbatim}

\sphinxAtStartPar
Data can be constructed as a numpy array

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} create an array of data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{2000}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} get an array of data from a sin function }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{targ} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sin}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
To use the basic method interface, the data must be labeled

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} define a segment within the sine wave to use as reference}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{t\PYGZus{}s}\PYG{p}{,}\PYG{n}{t\PYGZus{}e} \PYG{o}{=} \PYG{l+m+mi}{200}\PYG{p}{,}\PYG{l+m+mi}{400}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} cut a segment out to use as a reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{refData} \PYG{o}{=} \PYG{p}{[} \PYG{p}{\PYGZob{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{0}\PYG{l+s+s1}{\PYGZsq{}} \PYG{p}{:} \PYG{n}{targ}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]} \PYG{p}{\PYGZcb{}} \PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{targData} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{0}\PYG{l+s+s1}{\PYGZsq{}} \PYG{p}{:} \PYG{n}{targ}\PYG{p}{\PYGZcb{}} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{refWeights} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{0}\PYG{l+s+s1}{\PYGZsq{}} \PYG{p}{:} \PYG{l+m+mi}{1}\PYG{p}{\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} define some test parameters}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{minWin} \PYG{o}{=} \PYG{l+m+mi}{98} \PYG{c+c1}{\PYGZsh{}minimum percent to scale down reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{maxWin} \PYG{o}{=} \PYG{l+m+mi}{105} \PYG{c+c1}{\PYGZsh{}maximum percent to scale up reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{sizeStep} \PYG{o}{=} \PYG{l+m+mi}{1} \PYG{c+c1}{\PYGZsh{}step to use for correlating reference to target data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}call the segmentation algorithm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{segments} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{segment\PYGZus{}data}\PYG{p}{(}\PYG{n}{refData}\PYG{p}{,}\PYG{n}{targData}\PYG{p}{,}\PYG{n}{refWeights}\PYG{p}{,}\PYG{n}{minWin}\PYG{p}{,}\PYG{n}{maxWin}\PYG{p}{,}\PYG{n}{sizeStep}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{segments}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{g+go}{array([[2.000000e+02, 4.000000e+02, 1.000000e+00],}
\PYG{g+go}{       [1.200000e+03, 1.398000e+03, 9.999999e\PYGZhy{}01]])}
\end{sphinxVerbatim}

\sphinxAtStartPar
Using matplotlib we can visualize the results

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} plot the full sine wave}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.2}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Target}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} plot the original reference segment}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{8}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.7}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Reference}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 
\PYG{g+go}{\PYGZgt{}\PYGZgt{}\PYGZgt{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} plot all segments found}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{seg\PYGZus{}num} \PYG{o}{=} \PYG{l+m+mi}{1}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{s}\PYG{p}{,}\PYG{n}{e}\PYG{p}{,}\PYG{n}{c} \PYG{o+ow}{in} \PYG{n}{segments}\PYG{p}{:}
\PYG{g+gp}{... }    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{n}{s}\PYG{p}{:}\PYG{n}{e}\PYG{p}{]}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{[}\PYG{n}{s}\PYG{p}{:}\PYG{n}{e}\PYG{p}{]}\PYG{p}{,}\PYG{n}{dashes}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.8}\PYG{p}{,} 
\PYG{g+gp}{... }    \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Segment }\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{seg\PYGZus{}num}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{... }    \PYG{n}{seg\PYGZus{}num} \PYG{o}{+}\PYG{o}{=} \PYG{l+m+mi}{1} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Angle [rad]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sin(x)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{tight\PYGZus{}layout}\PYG{p}{(}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)} 
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{start-1}.pdf}
\end{figure}


\subsection{Gauss}
\label{\detokenize{start:gauss}}
\sphinxAtStartPar
In this example a Gaussian pulse is used to show segmentation on the varying shape of different amplitude.
As the center arc is given as reference, the multiple extending arcs are found as well. Through
the output of the segments, the correlation values can be seen to decrease, although still
clustered within the group.

\phantomsection\label{\detokenize{start:module-seg1d.examples.ex_gauss}}\index{module@\spxentry{module}!seg1d.examples.ex\_gauss@\spxentry{seg1d.examples.ex\_gauss}}\index{seg1d.examples.ex\_gauss@\spxentry{seg1d.examples.ex\_gauss}!module@\spxentry{module}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pylab} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{signal} \PYG{k}{as} \PYG{n+nn}{signal} 
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} create an array of data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2000}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} get an array of data from a Gaussian pulse }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{targ} \PYG{o}{=} \PYG{n}{signal}\PYG{o}{.}\PYG{n}{gausspulse}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{fc}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} define a segment within the sine wave to use as reference}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{t\PYGZus{}s}\PYG{p}{,}\PYG{n}{t\PYGZus{}e}    \PYG{o}{=} \PYG{l+m+mi}{950}\PYG{p}{,}\PYG{l+m+mi}{1050}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} cut a segment out to use as a reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{refData}    \PYG{o}{=} \PYG{p}{[} \PYG{p}{\PYGZob{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gauss}\PYG{l+s+s1}{\PYGZsq{}} \PYG{p}{:} \PYG{n}{targ}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]} \PYG{p}{\PYGZcb{}} \PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{targData}   \PYG{o}{=}   \PYG{p}{\PYGZob{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gauss}\PYG{l+s+s1}{\PYGZsq{}} \PYG{p}{:} \PYG{n}{targ} \PYG{p}{\PYGZcb{}} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{refWeights} \PYG{o}{=}   \PYG{p}{\PYGZob{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gauss}\PYG{l+s+s1}{\PYGZsq{}} \PYG{p}{:} \PYG{l+m+mi}{1} \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{} define some test parameters}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{minWin}   \PYG{o}{=} \PYG{l+m+mi}{98} \PYG{c+c1}{\PYGZsh{}minimum percent to scale down reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{maxWin}   \PYG{o}{=} \PYG{l+m+mi}{105} \PYG{c+c1}{\PYGZsh{}maximum percent to scale up reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{sizeStep} \PYG{o}{=} \PYG{l+m+mi}{1} \PYG{c+c1}{\PYGZsh{}step to use for correlating reference to target data}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} call the segmentation algorithm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{segments} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{segment\PYGZus{}data}\PYG{p}{(}\PYG{n}{refData}\PYG{p}{,}\PYG{n}{targData}\PYG{p}{,}\PYG{n}{refWeights}\PYG{p}{,}\PYG{n}{minWin}\PYG{p}{,}\PYG{n}{maxWin}\PYG{p}{,}\PYG{n}{sizeStep}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{segments}\PYG{p}{,}\PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{[[9.500000e+02 1.050000e+03 1.000000e+00]}
\PYG{g+go}{ [1.146000e+03 1.245000e+03 9.867665e\PYGZhy{}01]}
\PYG{g+go}{ [7.550000e+02 8.540000e+02 9.867665e\PYGZhy{}01]}
\PYG{g+go}{ [1.343000e+03 1.441000e+03 9.498135e\PYGZhy{}01]}
\PYG{g+go}{ [5.590000e+02 6.570000e+02 9.498135e\PYGZhy{}01]}
\PYG{g+go}{ [1.540000e+03 1.638000e+03 8.949109e\PYGZhy{}01]}
\PYG{g+go}{ [3.620000e+02 4.600000e+02 8.949109e\PYGZhy{}01]}
\PYG{g+go}{ [1.738000e+03 1.836000e+03 8.301899e\PYGZhy{}01]}
\PYG{g+go}{ [1.640000e+02 2.620000e+02 8.301899e\PYGZhy{}01]]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} plot the full pulse}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.2}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Target}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} plot the original reference segment}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{8}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Reference}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} plot all segments found}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{seg\PYGZus{}num} \PYG{o}{=} \PYG{l+m+mi}{1}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{s}\PYG{p}{,}\PYG{n}{e}\PYG{p}{,}\PYG{n}{c} \PYG{o+ow}{in} \PYG{n}{segments}\PYG{p}{:}
\PYG{g+gp}{... }    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{n}{s}\PYG{p}{:}\PYG{n}{e}\PYG{p}{]}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{[}\PYG{n}{s}\PYG{p}{:}\PYG{n}{e}\PYG{p}{]}\PYG{p}{,}\PYG{n}{dashes}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{l+m+mf}{0.5}\PYG{p}{]}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.8}\PYG{p}{,} 
\PYG{g+gp}{... }    \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Segment }\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{seg\PYGZus{}num}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{... }    \PYG{n}{seg\PYGZus{}num} \PYG{o}{+}\PYG{o}{=} \PYG{l+m+mi}{1} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)} 
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{start-2}.pdf}
\end{figure}


\section{API Examples}
\label{\detokenize{api:api-examples}}\label{\detokenize{api::doc}}
\sphinxAtStartPar
seg1d can be used through both the routines and through the \sphinxcode{\sphinxupquote{Segmenter}} class,
which provides various methods for constructing a segmenter by setting parameters and data.

\sphinxAtStartPar
This section contains the more advanced usage of the package by creating an instance
of the class. The usage is explained through different sample datasets, both of real
and generated data. Each example emphasizes a different aspect of the segmentation process.
\subsubsection*{API Examples}


\subsection{Basic Use}
\label{\detokenize{api_basic:module-seg1d.examples.ex_segmenter_sine}}\label{\detokenize{api_basic:basic-use}}\label{\detokenize{api_basic::doc}}\index{module@\spxentry{module}!seg1d.examples.ex\_segmenter\_sine@\spxentry{seg1d.examples.ex\_segmenter\_sine}}\index{seg1d.examples.ex\_segmenter\_sine@\spxentry{seg1d.examples.ex\_segmenter\_sine}!module@\spxentry{module}}
\sphinxAtStartPar
An example of instancing the Segmenter class to use the convenience methods on array data

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pylab} \PYG{k}{as} \PYG{n+nn}{plt}
\end{sphinxVerbatim}

\sphinxAtStartPar
Then we generate some data

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{2000}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}create an array of data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{targ} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sin}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} target data from a sin function }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{t\PYGZus{}s}\PYG{p}{,}\PYG{n}{t\PYGZus{}e} \PYG{o}{=} \PYG{l+m+mi}{200}\PYG{p}{,}\PYG{l+m+mi}{400} \PYG{c+c1}{\PYGZsh{} define a sub\PYGZhy{}series}
\end{sphinxVerbatim}

\sphinxAtStartPar
To assign the data to the Segmenter, first we create an instance of it and then
use the \sphinxcode{\sphinxupquote{set\_target()}} and \sphinxcode{\sphinxupquote{add\_reference()}} methods.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{Segmenter}\PYG{p}{(}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} instance of the segmenter}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{minW}\PYG{p}{,} \PYG{n}{s}\PYG{o}{.}\PYG{n}{maxW}\PYG{p}{,} \PYG{n}{s}\PYG{o}{.}\PYG{n}{step} \PYG{o}{=} \PYG{l+m+mi}{98}\PYG{p}{,} \PYG{l+m+mi}{105}\PYG{p}{,} \PYG{l+m+mi}{1}  \PYG{c+c1}{\PYGZsh{} scaling parameters}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{set\PYGZus{}target}\PYG{p}{(}\PYG{n}{targ}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} set target and reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{add\PYGZus{}reference}\PYG{p}{(}\PYG{n}{targ}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{segments} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{segment}\PYG{p}{(}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} run segmentation algorithm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{segments}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{g+go}{array([[2.000000e+02, 4.000000e+02, 1.000000e+00],}
\PYG{g+go}{       [1.200000e+03, 1.398000e+03, 9.999999e\PYGZhy{}01]])}
\end{sphinxVerbatim}

\sphinxAtStartPar
Using matplotlib we can visualize the results

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}plot the full sine wave}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{8}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.2}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Target}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}plot the original reference segment}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.7}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Reference}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 
\PYG{g+go}{\PYGZgt{}\PYGZgt{}\PYGZgt{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}plot all segments found}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{seg\PYGZus{}num} \PYG{o}{=} \PYG{l+m+mi}{1}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{s}\PYG{p}{,}\PYG{n}{e}\PYG{p}{,}\PYG{n}{c} \PYG{o+ow}{in} \PYG{n}{segments}\PYG{p}{:}
\PYG{g+gp}{... }    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{n}{s}\PYG{p}{:}\PYG{n}{e}\PYG{p}{]}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{[}\PYG{n}{s}\PYG{p}{:}\PYG{n}{e}\PYG{p}{]}\PYG{p}{,}\PYG{n}{dashes}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.8}\PYG{p}{,} 
\PYG{g+gp}{... }    \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Segment }\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{seg\PYGZus{}num}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{... }    \PYG{n}{seg\PYGZus{}num} \PYG{o}{+}\PYG{o}{=} \PYG{l+m+mi}{1} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Angle [rad]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sin(x)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{tight\PYGZus{}layout}\PYG{p}{(}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)} 
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_basic-1}.pdf}
\end{figure}


\subsection{ECG}
\label{\detokenize{api_ecg:module-seg1d.examples.ex_ecg}}\label{\detokenize{api_ecg:ecg}}\label{\detokenize{api_ecg::doc}}\index{module@\spxentry{module}!seg1d.examples.ex\_ecg@\spxentry{seg1d.examples.ex\_ecg}}\index{seg1d.examples.ex\_ecg@\spxentry{seg1d.examples.ex\_ecg}!module@\spxentry{module}}
\sphinxAtStartPar
In this example we use the ECG data included with scipy signal module. 
The references roughly includes the Q\sphinxhyphen{}T interval (\sphinxurl{https://en.wikipedia.org/wiki/Electrocardiography}).
In the first portion, two sample segments are used. While the segments are not aligned, they are able to find some segments correctly. 
In the second portion of the example, only one segment is used for the reference data.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{random}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{misc} \PYG{k+kn}{import} \PYG{n}{electrocardiogram}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d} 
\end{sphinxVerbatim}

\sphinxAtStartPar
After imports, the scipy signal ECG data is called and some segments are taken.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ecg} \PYG{o}{=} \PYG{n}{electrocardiogram}\PYG{p}{(}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}get the scipy sample data }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ref\PYGZus{}slices} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{927}\PYG{p}{,} \PYG{l+m+mi}{1057}\PYG{p}{]}\PYG{p}{,}\PYG{p}{[}\PYG{l+m+mi}{1111}\PYG{p}{,} \PYG{l+m+mi}{1229}\PYG{p}{]}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{}pick sample endpoints}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{Segmenter}\PYG{p}{(}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{}create the segmenter}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{refs} \PYG{o}{=} \PYG{p}{[} \PYG{n}{ecg}\PYG{p}{[}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{:}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{]} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{ref\PYGZus{}slices} \PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{r} \PYG{o+ow}{in} \PYG{n}{refs}\PYG{p}{:} \PYG{n}{s}\PYG{o}{.}\PYG{n}{add\PYGZus{}reference}\PYG{p}{(}\PYG{n}{r}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}set reference data}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{set\PYGZus{}target}\PYG{p}{(}\PYG{n}{ecg}\PYG{p}{[}\PYG{l+m+mi}{1500}\PYG{p}{:}\PYG{l+m+mi}{3500}\PYG{p}{]}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}set the target data to the ecg after ref}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{segments} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{segment}\PYG{p}{(}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} run segmenter with defaults}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{segments}\PYG{p}{,}\PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{[[1.607000e+03 1.729000e+03 8.169533e\PYGZhy{}01]}
\PYG{g+go}{ [7.380000e+02 8.220000e+02 8.123868e\PYGZhy{}01]}
\PYG{g+go}{ [9.190000e+02 1.003000e+03 8.120505e\PYGZhy{}01]}
\PYG{g+go}{ [1.439000e+03 1.552000e+03 8.092366e\PYGZhy{}01]}
\PYG{g+go}{ [3.600000e+02 4.930000e+02 8.077664e\PYGZhy{}01]}
\PYG{g+go}{ [1.091000e+03 1.213000e+03 8.043364e\PYGZhy{}01]}
\PYG{g+go}{ [1.775000e+03 1.895000e+03 7.998723e\PYGZhy{}01]}
\PYG{g+go}{ [1.720000e+02 3.000000e+02 7.926582e\PYGZhy{}01]}
\PYG{g+go}{ [1.268000e+03 1.340000e+03 7.847107e\PYGZhy{}01]}
\PYG{g+go}{ [5.540000e+02 6.280000e+02 7.802931e\PYGZhy{}01]]}
\end{sphinxVerbatim}

\sphinxAtStartPar
The reference data is automatically scaled to the largest reference in the dataset
when the \sphinxcode{\sphinxupquote{segment}} method is called. Therefore, by retrieving this attribute
we can plot what the reference set looks like when the lengths are normalized.

\sphinxAtStartPar
In the example, it is clear the peaks of the reference segments are not aligned. 
This discrepency, due to the averaging of all reference data items, will be seen
in the final segments of the target data later.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{refs} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{r}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{refs} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{asarray}\PYG{p}{(} \PYG{p}{[} \PYG{n}{x}\PYG{p}{[}\PYG{n}{y}\PYG{p}{]} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{refs} \PYG{k}{for} \PYG{n}{y} \PYG{o+ow}{in} \PYG{n}{x} \PYG{p}{]} \PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{refs}\PYG{o}{.}\PYG{n}{T}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{time in s}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ECG in mV}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{tight\PYGZus{}layout}\PYG{p}{(}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}  
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_ecg-1}.pdf}
\end{figure}

\sphinxAtStartPar
The final segments are shown by calling the property \sphinxcode{\sphinxupquote{t\_masked}} which returns the 
target data as an ndarray with NaN values for areas not found to be segments.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{s}\PYG{o}{.}\PYG{n}{t\PYGZus{}masked}\PYG{o}{.}\PYG{n}{T}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{time in s}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ECG in mV}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{tight\PYGZus{}layout}\PYG{p}{(}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}  
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_ecg-2}.pdf}
\end{figure}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}use only 1 reference}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{clear\PYGZus{}reference}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{add\PYGZus{}reference}\PYG{p}{(} \PYG{n}{ecg}\PYG{p}{[}\PYG{l+m+mi}{927}\PYG{p}{:}\PYG{l+m+mi}{1057}\PYG{p}{]} \PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{refs} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{r}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{refs} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{asarray}\PYG{p}{(} \PYG{p}{[} \PYG{n}{x}\PYG{p}{[}\PYG{n}{y}\PYG{p}{]} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{refs} \PYG{k}{for} \PYG{n}{y} \PYG{o+ow}{in} \PYG{n}{x} \PYG{p}{]} \PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{refs}\PYG{o}{.}\PYG{n}{T}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{time in s}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ECG in mV}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{tight\PYGZus{}layout}\PYG{p}{(}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}  
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_ecg-3}.pdf}
\end{figure}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}remove first part of data (contains reference)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{set\PYGZus{}target}\PYG{p}{(}\PYG{n}{ecg}\PYG{p}{[}\PYG{l+m+mi}{1500}\PYG{p}{:}\PYG{l+m+mi}{3500}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{nC} \PYG{o}{=} \PYG{l+m+mi}{2}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{cMin} \PYG{o}{=} \PYG{l+m+mf}{0.7}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{segments} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{segment}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{segments}\PYG{p}{,}\PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{[[7.350000e+02 8.540000e+02 9.462850e\PYGZhy{}01]}
\PYG{g+go}{ [1.093000e+03 1.213000e+03 9.242974e\PYGZhy{}01]}
\PYG{g+go}{ [9.140000e+02 1.046000e+03 9.059727e\PYGZhy{}01]}
\PYG{g+go}{ [3.620000e+02 4.980000e+02 9.009127e\PYGZhy{}01]}
\PYG{g+go}{ [5.470000e+02 6.800000e+02 8.940106e\PYGZhy{}01]}
\PYG{g+go}{ [1.262000e+03 1.390000e+03 8.868629e\PYGZhy{}01]}
\PYG{g+go}{ [1.776000e+03 1.902000e+03 8.771139e\PYGZhy{}01]}
\PYG{g+go}{ [1.609000e+03 1.729000e+03 8.689476e\PYGZhy{}01]}
\PYG{g+go}{ [1.440000e+03 1.559000e+03 8.646669e\PYGZhy{}01]}
\PYG{g+go}{ [1.730000e+02 3.060000e+02 8.029426e\PYGZhy{}01]]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{res} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{t\PYGZus{}masked}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{res}\PYG{o}{.}\PYG{n}{T}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{time in s}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{ECG in mV}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{tight\PYGZus{}layout}\PYG{p}{(}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}  
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_ecg-4}.pdf}
\end{figure}


\subsection{Feature Inclusion}
\label{\detokenize{api_feat:feature-inclusion}}\label{\detokenize{api_feat::doc}}
\sphinxAtStartPar
There may be a case where an original dataset has multiple features, but only a subset
of these features are wanted to be included in the segmentation process.

\phantomsection\label{\detokenize{api_feat:module-seg1d.examples.ex_segmenter_features}}\index{module@\spxentry{module}!seg1d.examples.ex\_segmenter\_features@\spxentry{seg1d.examples.ex\_segmenter\_features}}\index{seg1d.examples.ex\_segmenter\_features@\spxentry{seg1d.examples.ex\_segmenter\_features}!module@\spxentry{module}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pylab} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d} 
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}retrieve the sample reference, target, and weight data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{r}\PYG{p}{,}\PYG{n}{t}\PYG{p}{,}\PYG{n}{w} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{sampleData}\PYG{p}{(}\PYG{n}{c}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Note: The reference data shown here is centered at 0 on the y axis (vertical).
As the algorithm process is based on the shape of the curve, it is irrelevant
what this offset is.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} plot reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt\PYGZus{}r} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{asarray}\PYG{p}{(} \PYG{p}{[} \PYG{n}{x} \PYG{k}{for} \PYG{n}{y} \PYG{o+ow}{in} \PYG{n}{r} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{y}\PYG{o}{.}\PYG{n}{values}\PYG{p}{(}\PYG{p}{)}  \PYG{p}{]}  \PYG{p}{)}\PYG{o}{.}\PYG{n}{T}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{plt\PYGZus{}r}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.3}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)} 
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_feat-1}.pdf}
\end{figure}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} plot target data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt\PYGZus{}t} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{asarray}\PYG{p}{(} \PYG{p}{[} \PYG{n}{x} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{t}\PYG{o}{.}\PYG{n}{values}\PYG{p}{(}\PYG{p}{)} \PYG{p}{]} \PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{plt\PYGZus{}t}\PYG{o}{.}\PYG{n}{T}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)} 
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_feat-2}.pdf}
\end{figure}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}Make an instance of the segmenter}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{Segmenter}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}set scaling parameters}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{minW}\PYG{p}{,}\PYG{n}{s}\PYG{o}{.}\PYG{n}{maxW}\PYG{p}{,}\PYG{n}{s}\PYG{o}{.}\PYG{n}{step} \PYG{o}{=} \PYG{l+m+mi}{98}\PYG{p}{,} \PYG{l+m+mi}{105}\PYG{p}{,} \PYG{l+m+mi}{1}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}Set target and reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{t}\PYG{p}{,} \PYG{n}{s}\PYG{o}{.}\PYG{n}{r}\PYG{p}{,} \PYG{n}{s}\PYG{o}{.}\PYG{n}{w} \PYG{o}{=} \PYG{n}{t}\PYG{p}{,}\PYG{n}{r}\PYG{p}{,}\PYG{n}{w}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}call the segmentation algorithm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{segments} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{segment}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{segments}\PYG{p}{,}\PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{[[204.        245.          0.7128945]}
\PYG{g+go}{ [ 70.        112.          0.6670482]}
\PYG{g+go}{ [340.        382.          0.6630886]]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt\PYGZus{}t} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{t\PYGZus{}masked} \PYG{c+c1}{\PYGZsh{}get a NaN masked array of the target data}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} plot masked target}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{plt\PYGZus{}t}\PYG{o}{.}\PYG{n}{T}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)} 
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_feat-3}.pdf}
\end{figure}

\sphinxAtStartPar
To use a subset of the features, the weights can be redefined, 
which may result in a different segmentation result

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{sub} \PYG{o}{=} \PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C7}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{z}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{T10}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{z}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{CLAV}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{z}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{w} \PYG{o}{=} \PYG{p}{\PYGZob{}} \PYG{n}{x}\PYG{p}{:} \PYG{n}{w}\PYG{p}{[}\PYG{n}{x}\PYG{p}{]} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{sub} \PYG{p}{\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{segments} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{segment}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{segments}\PYG{p}{,}\PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{[[  2.         44.          0.9648465]}
\PYG{g+go}{ [341.        383.          0.9646419]}
\PYG{g+go}{ [203.        244.          0.9644605]}
\PYG{g+go}{ [273.        314.          0.9640178]}
\PYG{g+go}{ [ 72.        113.          0.9632458]}
\PYG{g+go}{ [139.        180.          0.9624551]]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt\PYGZus{}t} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{t\PYGZus{}masked} \PYG{c+c1}{\PYGZsh{}get a NaN masked array of the target data}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} plot masked target}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{plt\PYGZus{}t}\PYG{o}{.}\PYG{n}{T}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)} 
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_feat-4}.pdf}
\end{figure}


\subsection{Parameter Tuning}
\label{\detokenize{api_tune:parameter-tuning}}\label{\detokenize{api_tune::doc}}
\sphinxAtStartPar
In some cases, the default values used in the segmentation process
do not result in the desired results. In this case, the various parameters
that are invovled can be manually set by the user. These parameters are
all defined and available through the \sphinxcode{\sphinxupquote{seg1d.Segmenter()}} class.

\phantomsection\label{\detokenize{api_tune:module-seg1d.examples.ex_sine_noise}}\index{module@\spxentry{module}!seg1d.examples.ex\_sine\_noise@\spxentry{seg1d.examples.ex\_sine\_noise}}\index{seg1d.examples.ex\_sine\_noise@\spxentry{seg1d.examples.ex\_sine\_noise}!module@\spxentry{module}}
\sphinxAtStartPar
In this example, the attributes of the segmentation algorithm will be 
demonstrated through a sine wave with added noise. In this example, the 
seed used for the random noise is the same in both the target and reference, 
although a different SNR is used.

\sphinxAtStartPar
First we import \sphinxcode{\sphinxupquote{seg1d}}, a helper function for adding noise in the example called 
\sphinxcode{\sphinxupquote{segnoise}}, and the plotting utils from \sphinxcode{\sphinxupquote{matplotlib}}.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pylab} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}\PYG{n+nn}{.}\PYG{n+nn}{examples}\PYG{n+nn}{.}\PYG{n+nn}{noise} \PYG{k}{as} \PYG{n+nn}{segnoise}
\end{sphinxVerbatim}

\sphinxAtStartPar
Next an array of data is generated and a sine wave is created. 
A signal\sphinxhyphen{}noise ratio of 30 is added to the sine wave.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} create an array of data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{2000}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} get an array of data from a sin function }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{targ} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sin}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} add noise to the signal }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{123}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{targ} \PYG{o}{=} \PYG{n}{segnoise}\PYG{o}{.}\PYG{n}{add\PYGZus{}noise}\PYG{p}{(}\PYG{n}{targ}\PYG{p}{,}\PYG{n}{snr}\PYG{o}{=}\PYG{l+m+mi}{30}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
The target data that is used for finding segments in looks like:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} Plot the target}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Target}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Angle [rad]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sin(x)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{tight\PYGZus{}layout}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_tune-1}.pdf}
\end{figure}

\sphinxAtStartPar
Now another noisy sine wave is created and a segment of it is cut out.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} define a segment within the sine wave to use as reference}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{t\PYGZus{}s}\PYG{p}{,}\PYG{n}{t\PYGZus{}e} \PYG{o}{=} \PYG{l+m+mi}{200}\PYG{p}{,}\PYG{l+m+mi}{400}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} number of reference datasets to generate for the example}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} make reference data with different random noise on a segment of the original}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{123}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{refData} \PYG{o}{=} \PYG{n}{segnoise}\PYG{o}{.}\PYG{n}{add\PYGZus{}noise}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{sin}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{,}\PYG{n}{snr}\PYG{o}{=}\PYG{l+m+mi}{45}\PYG{p}{)}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]} 
\end{sphinxVerbatim}

\sphinxAtStartPar
The reference data looks like:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} Plot the reference}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]}\PYG{p}{,} \PYG{n}{refData}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Reference}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Angle [rad]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sin(x)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{tight\PYGZus{}layout}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_tune-2}.pdf}
\end{figure}

\sphinxAtStartPar
To find the sub\sphinxhyphen{}series segment, an instance of the \sphinxcode{\sphinxupquote{Segmenter}} class is created,
basic scaling parameters, and the target and reference data are assigned.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} Make an instance of the segmenter}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{Segmenter}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}set scaling parameters}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{minW}\PYG{p}{,}\PYG{n}{s}\PYG{o}{.}\PYG{n}{maxW}\PYG{p}{,}\PYG{n}{s}\PYG{o}{.}\PYG{n}{step} \PYG{o}{=} \PYG{l+m+mi}{90}\PYG{p}{,} \PYG{l+m+mi}{110}\PYG{p}{,} \PYG{l+m+mi}{1}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}Set target and reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{set\PYGZus{}target}\PYG{p}{(}\PYG{n}{targ}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{add\PYGZus{}reference}\PYG{p}{(}\PYG{n}{refData}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}call the segmentation algorithm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{segments} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{segment}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{segments}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{g+go}{array([[1.200000e+03, 1.420000e+03, 9.916268e\PYGZhy{}01],}
\PYG{g+go}{       [2.000000e+02, 4.000000e+02, 9.904041e\PYGZhy{}01],}
\PYG{g+go}{       [4.000000e+02, 5.820000e+02, 8.933443e\PYGZhy{}01],}
\PYG{g+go}{       [1.421000e+03, 1.601000e+03, 8.833249e\PYGZhy{}01]])}
\end{sphinxVerbatim}

\sphinxAtStartPar
After running the segmentation algorithm, we plot the segment the reference 
data should be located, along with the segments that were found.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}plot the full sine wave}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.2}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Target}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}plot the location of the original reference segment }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} NOTE this is just the location, the actual reference data is shown above}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.7}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Reference}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}plot all segments found}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{seg\PYGZus{}num} \PYG{o}{=} \PYG{l+m+mi}{1}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{seg} \PYG{o+ow}{in} \PYG{n}{segments}\PYG{p}{:}
\PYG{g+gp}{... }    \PYG{n}{st} \PYG{o}{=} \PYG{n}{seg}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{g+gp}{... }    \PYG{n}{e} \PYG{o}{=} \PYG{n}{seg}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{g+gp}{... }    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{n}{st}\PYG{p}{:}\PYG{n}{e}\PYG{p}{]}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{[}\PYG{n}{st}\PYG{p}{:}\PYG{n}{e}\PYG{p}{]}\PYG{p}{,}\PYG{n}{dashes}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.8}\PYG{p}{,} 
\PYG{g+gp}{... }    \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Segment }\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{seg\PYGZus{}num}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{... }    \PYG{n}{seg\PYGZus{}num} \PYG{o}{+}\PYG{o}{=} \PYG{l+m+mi}{1}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Angle [rad]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sin(x)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{tight\PYGZus{}layout}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_tune-3}.pdf}
\end{figure}

\sphinxAtStartPar
From the plot, it is clear there are segments that do not belong. 
By accessing the \sphinxcode{\sphinxupquote{Segmenter}} attributes, the algorithm and this error are better understood (and resolved).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} First we look at the original segments before clustering}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{s}\PYG{o}{.}\PYG{n}{groups}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{g+go}{array([[1.200000e+03, 1.420000e+03, 9.916268e\PYGZhy{}01],}
\PYG{g+go}{       [2.000000e+02, 4.000000e+02, 9.904041e\PYGZhy{}01],}
\PYG{g+go}{       [4.000000e+02, 5.820000e+02, 8.933443e\PYGZhy{}01],}
\PYG{g+go}{       [1.421000e+03, 1.601000e+03, 8.833249e\PYGZhy{}01],}
\PYG{g+go}{       [5.830000e+02, 7.650000e+02, 7.286635e\PYGZhy{}01],}
\PYG{g+go}{       [1.602000e+03, 1.782000e+03, 6.541974e\PYGZhy{}01]])}
\end{sphinxVerbatim}

\sphinxAtStartPar
As shown in the output, there are a total of 6 segments found before clustering.

\sphinxAtStartPar
As the distribution of segments is apporx. {[}0.99,0.99,0.89,0.88,0.72,0.65{]}, 
the attribute, \sphinxcode{\sphinxupquote{Segmenter.cAdd}}, (defaults to 0.5) that is added for forcing clusters 
only combines the last two values, 0.72 and 0.65 in the lower cluser.

\sphinxAtStartPar
Modifying this attribute would then change the clusters, for example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{cAdd} \PYG{o}{=} \PYG{l+m+mf}{0.8}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{s}\PYG{o}{.}\PYG{n}{segment}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{g+go}{array([[1.200000e+03, 1.420000e+03, 9.916268e\PYGZhy{}01],}
\PYG{g+go}{       [2.000000e+02, 4.000000e+02, 9.904041e\PYGZhy{}01]])}
\end{sphinxVerbatim}

\sphinxAtStartPar
If the attribute is removed, then only the original segments are used in the clustering. 
However, this results in the same cluster as the original where the default of \sphinxcode{\sphinxupquote{cAdd}} was 0.5.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{cAdd} \PYG{o}{=} \PYG{k+kc}{None}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{s}\PYG{o}{.}\PYG{n}{segment}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{g+go}{array([[1.200000e+03, 1.420000e+03, 9.916268e\PYGZhy{}01],}
\PYG{g+go}{       [2.000000e+02, 4.000000e+02, 9.904041e\PYGZhy{}01],}
\PYG{g+go}{       [4.000000e+02, 5.820000e+02, 8.933443e\PYGZhy{}01],}
\PYG{g+go}{       [1.421000e+03, 1.601000e+03, 8.833249e\PYGZhy{}01]])}
\end{sphinxVerbatim}

\sphinxAtStartPar
Alternatively, the minimum correlation for a given segment can be set with the \sphinxcode{\sphinxupquote{Segmenter.cMin}} attribute.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{cMin} \PYG{o}{=} \PYG{l+m+mf}{0.9}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{s}\PYG{o}{.}\PYG{n}{segment}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}\PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{g+go}{array([[1.200000e+03, 1.420000e+03, 9.916268e\PYGZhy{}01]])}
\end{sphinxVerbatim}

\sphinxAtStartPar
Since the \sphinxcode{\sphinxupquote{cAdd}} was removed, the only segments available (higher than 0.9 correlation) 
were both 0.99, making the clustering result in a single segment.

\sphinxAtStartPar
If \sphinxcode{\sphinxupquote{cAdd}} is set back to the default, the segment is correct.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{cAdd} \PYG{o}{=} \PYG{l+m+mf}{0.5}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{segments} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{segment}\PYG{p}{(}\PYG{p}{)} 
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{segments}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{g+go}{array([[1.200000e+03, 1.420000e+03, 9.916268e\PYGZhy{}01],}
\PYG{g+go}{       [2.000000e+02, 4.000000e+02, 9.904041e\PYGZhy{}01]])}
\end{sphinxVerbatim}

\sphinxAtStartPar
Finally, plotting these segments shows the alignment and logical sub\sphinxhyphen{}series
identification.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}plot the full sine wave}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.2}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Target}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}plot the original reference segment}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{[}\PYG{n}{t\PYGZus{}s}\PYG{p}{:}\PYG{n}{t\PYGZus{}e}\PYG{p}{]}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.7}\PYG{p}{,}\PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Reference}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}plot all segments found}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{seg\PYGZus{}num} \PYG{o}{=} \PYG{l+m+mi}{1}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{seg} \PYG{o+ow}{in} \PYG{n}{segments}\PYG{p}{:}
\PYG{g+gp}{... }    \PYG{n}{st} \PYG{o}{=} \PYG{n}{seg}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{g+gp}{... }    \PYG{n}{e} \PYG{o}{=} \PYG{n}{seg}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{g+gp}{... }    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{n}{st}\PYG{p}{:}\PYG{n}{e}\PYG{p}{]}\PYG{p}{,} \PYG{n}{targ}\PYG{p}{[}\PYG{n}{st}\PYG{p}{:}\PYG{n}{e}\PYG{p}{]}\PYG{p}{,}\PYG{n}{dashes}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}\PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.8}\PYG{p}{,} 
\PYG{g+gp}{... }    \PYG{n}{label}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Segment }\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{seg\PYGZus{}num}\PYG{p}{)}\PYG{p}{)} 
\PYG{g+gp}{... }    \PYG{n}{seg\PYGZus{}num} \PYG{o}{+}\PYG{o}{=} \PYG{l+m+mi}{1}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Angle [rad]}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{sin(x)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{tight\PYGZus{}layout}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_tune-4}.pdf}
\end{figure}


\subsection{Feature Processing}
\label{\detokenize{api_processing:feature-processing}}\label{\detokenize{api_processing::doc}}
\sphinxAtStartPar
If there is a series of references that have different lengths, or the weighting is unknown,
this example can help guide users to process the data.

\phantomsection\label{\detokenize{api_processing:module-seg1d.examples.ex_feature_processing}}\index{module@\spxentry{module}!seg1d.examples.ex\_feature\_processing@\spxentry{seg1d.examples.ex\_feature\_processing}}\index{seg1d.examples.ex\_feature\_processing@\spxentry{seg1d.examples.ex\_feature\_processing}!module@\spxentry{module}}
\sphinxAtStartPar
In this example we use a few utilities provided by {\hyperref[\detokenize{code:module-seg1d}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{seg1d}}}}} to process raw data. 
In many of the other examples, a reference set, target data, and weighting is assumed
or provided as sample.  If you have data from multiple sources, perhaps of different lengths of time
(or samples of points) or varying features, the data must be rescaled and parsed for the matching features.
This example also shows how to generate the feature weights, which will compare a set of references and find
the features most simliar between them (as a normalized sum of all features).

\sphinxAtStartPar
First we import numpy and matplotlib (to plot for the example)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\end{sphinxVerbatim}

\sphinxAtStartPar
Then import the base seg1d and the seg1d processing module

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}\PYG{n+nn}{.}\PYG{n+nn}{processing} \PYG{k}{as} \PYG{n+nn}{proc}
\end{sphinxVerbatim}

\sphinxAtStartPar
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#  SEG1D Processing \#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#

\sphinxAtStartPar
To start, we load an array of dictionaries provided as sample data in seg1d.
raw\_r is the set of references, and raw\_t is a set of targets

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{raw\PYGZus{}r}\PYG{p}{,} \PYG{n}{raw\PYGZus{}t} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{sample\PYGZus{}input\PYGZus{}data}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
First we can take a look at the reference datasets, noticing they are all different lengths

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{r} \PYG{o+ow}{in} \PYG{n}{raw\PYGZus{}r}\PYG{p}{:}
\PYG{g+gp}{... }    \PYG{n}{plt\PYGZus{}r} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{asarray}\PYG{p}{(} \PYG{p}{[} \PYG{n}{x} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{r}\PYG{o}{.}\PYG{n}{values}\PYG{p}{(}\PYG{p}{)}  \PYG{p}{]}  \PYG{p}{)}\PYG{o}{.}\PYG{n}{T}
\PYG{g+gp}{... }    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{plt\PYGZus{}r}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.3}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}  
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_processing-1}.pdf}
\end{figure}

\sphinxAtStartPar
Match feature length and center time series

\sphinxAtStartPar
The first function we use for pre\sphinxhyphen{}processing the data is \sphinxstyleemphasis{match\_len}. 
This will take the largest array of all reference datasets and rescale the other datasets 
to this longer size

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ref\PYGZus{}data} \PYG{o}{=} \PYG{n}{proc}\PYG{o}{.}\PYG{n}{Features}\PYG{o}{.}\PYG{n}{match\PYGZus{}len}\PYG{p}{(}\PYG{n}{raw\PYGZus{}r}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
We can now plot the length\sphinxhyphen{}matched datasets to see how the reference segments do show 
similarity over the same scaled timespan

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt\PYGZus{}r} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{asarray}\PYG{p}{(} \PYG{p}{[} \PYG{n}{x} \PYG{k}{for} \PYG{n}{y} \PYG{o+ow}{in} \PYG{n}{ref\PYGZus{}data} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{y}\PYG{o}{.}\PYG{n}{values}\PYG{p}{(}\PYG{p}{)}  \PYG{p}{]}  \PYG{p}{)}\PYG{o}{.}\PYG{n}{T}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{plt\PYGZus{}r}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.3}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}  
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_processing-2}.pdf}
\end{figure}

\sphinxAtStartPar
This next process is not always necessary, but is convenient to know. It simply shifts the mean
of each array in the references to center along the 0 axis.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ref\PYGZus{}data} \PYG{o}{=} \PYG{n}{proc}\PYG{o}{.}\PYG{n}{Features}\PYG{o}{.}\PYG{n}{center}\PYG{p}{(}\PYG{n}{ref\PYGZus{}data}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Make sure all reference data has valid keys
In this step, we use the \sphinxstyleemphasis{shared} function by passing all the datasets we will will use
to ensure no feature keys are missing. This requires a dictionary to map each feature correctly

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ref\PYGZus{}data}\PYG{p}{,} \PYG{n}{tar\PYGZus{}data} \PYG{o}{=} \PYG{n}{proc}\PYG{o}{.}\PYG{n}{Features}\PYG{o}{.}\PYG{n}{shared}\PYG{p}{(}\PYG{n}{ref\PYGZus{}data}\PYG{p}{,} \PYG{n}{raw\PYGZus{}t}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Generate weights from the segmented data
One of the most important steps for many use cases is the automatic weighting of multiple features.
The \sphinxstyleemphasis{gen\_weights} function takes a list of reference datasets and finds the features that match
best among all of the references.  It then normalizes all the results from 0 to 1. 
This is important to note, as it means some features will not be used. 
If all of your features are necessary or should be used, this function should be skipped.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{weights} \PYG{o}{=} \PYG{n}{proc}\PYG{o}{.}\PYG{n}{Features}\PYG{o}{.}\PYG{n}{gen\PYGZus{}weights}\PYG{p}{(}\PYG{n}{ref\PYGZus{}data}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Finally, the last step of pre\sphinxhyphen{}processing is to get which params to use and limit to specific ones. 
In this example, we take only the top 20 features, limit to the normalized score of 0.8, and pass
an empty list, which means we use all available features.  If there was a list of features
that you wanted to include, passing this key list of strings would be possible.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{weight\PYGZus{}dict} \PYG{o}{=} \PYG{n}{proc}\PYG{o}{.}\PYG{n}{Features}\PYG{o}{.}\PYG{n}{meaningful}\PYG{p}{(}\PYG{n}{weights}\PYG{p}{,} \PYG{n}{limit}\PYG{o}{=}\PYG{l+m+mf}{0.8}\PYG{p}{,} \PYG{n}{top}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{,} \PYG{n}{include\PYGZus{}keys}\PYG{o}{=}\PYG{p}{[}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Now we can take a look at the reference data that we will use for segmentation. 
This data has also been centered (a few steps before)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt\PYGZus{}r} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{asarray}\PYG{p}{(} \PYG{p}{[} \PYG{n}{x} \PYG{k}{for} \PYG{n}{y} \PYG{o+ow}{in} \PYG{n}{ref\PYGZus{}data} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{y}\PYG{o}{.}\PYG{n}{values}\PYG{p}{(}\PYG{p}{)}  \PYG{p}{]}  \PYG{p}{)}\PYG{o}{.}\PYG{n}{T}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{plt\PYGZus{}r}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.3}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}  
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_processing-3}.pdf}
\end{figure}

\sphinxAtStartPar
\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\# SEG1D Analysis \#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#

\sphinxAtStartPar
At this point the data is properly processed and features weighted. 
From here on, the normal segmentation process (as seen in the other examples) is applied.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{Segmenter}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{minW}\PYG{p}{,} \PYG{n}{s}\PYG{o}{.}\PYG{n}{maxW}\PYG{p}{,} \PYG{n}{s}\PYG{o}{.}\PYG{n}{step} \PYG{o}{=} \PYG{l+m+mi}{70}\PYG{p}{,} \PYG{l+m+mi}{150}\PYG{p}{,} \PYG{l+m+mi}{1}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{r} \PYG{o+ow}{in} \PYG{n}{ref\PYGZus{}data}\PYG{p}{:} 
\PYG{g+gp}{... }    \PYG{n}{s}\PYG{o}{.}\PYG{n}{add\PYGZus{}reference}\PYG{p}{(}\PYG{n}{r}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
As this sample dataset has multiple targets, we will just use the first one. 
However, you could iterate over all the target trials by wrapping the remaining code
under this example loop:
for idx, target in enumerate(tar\_data):

\sphinxAtStartPar
Run the analysis on the first target data.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{target} \PYG{o}{=} \PYG{n}{tar\PYGZus{}data}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\end{sphinxVerbatim}

\sphinxAtStartPar
We can visualize this target data before segmentation

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt\PYGZus{}t} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{asarray}\PYG{p}{(} \PYG{p}{[} \PYG{n}{x} \PYG{k}{for} \PYG{n}{x} \PYG{o+ow}{in} \PYG{n}{target}\PYG{o}{.}\PYG{n}{values}\PYG{p}{(}\PYG{p}{)} \PYG{p}{]} \PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{plt\PYGZus{}t}\PYG{o}{.}\PYG{n}{T}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}  
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_processing-4}.pdf}
\end{figure}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{set\PYGZus{}target}\PYG{p}{(}\PYG{n}{target}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{w} \PYG{o}{=} \PYG{n}{weight\PYGZus{}dict}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{segments} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{segment}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n+nb}{sorted}\PYG{p}{(}\PYG{n}{segments}\PYG{p}{,} \PYG{n}{key}\PYG{o}{=}\PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{3}\PYG{p}{]}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{[[ 42.       67.        0.99856]}
\PYG{g+go}{ [112.      137.        0.99864]}
\PYG{g+go}{ [181.      208.        0.99709]]}
\end{sphinxVerbatim}

\sphinxAtStartPar
Now that we have segmented the data, the masked array can be plotted to show the results.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt\PYGZus{}t} \PYG{o}{=} \PYG{n}{s}\PYG{o}{.}\PYG{n}{t\PYGZus{}masked} \PYG{c+c1}{\PYGZsh{}get a NaN masked array of the target data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} plot masked target}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{15}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{plt\PYGZus{}t}\PYG{o}{.}\PYG{n}{T}\PYG{p}{,}\PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{)}  
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}  
\end{sphinxVerbatim}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{api_processing-5}.pdf}
\end{figure}
\subsubsection*{See Also}

\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.Segmenter:seg1d.Segmenter}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{seg1d.Segmenter}}}}}


\section{Code Reference}
\label{\detokenize{code:code-reference}}\label{\detokenize{code::doc}}

\subsection{Simple Interface}
\label{\detokenize{code:simple-interface}}
\sphinxAtStartPar
This method is shown in the getting started section of the documentation. It provides an
easy\sphinxhyphen{}to\sphinxhyphen{}use interface for segmenting data, although it has limited functionality in
fine\sphinxhyphen{}tuning parameters of the underlying algorithms.


\subsubsection{Simple Interface}
\label{\detokenize{code_simple:simple-interface}}\label{\detokenize{code_simple::doc}}

\begin{fulllineitems}
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{seg1d.}}\sphinxbfcode{\sphinxupquote{segment\_data}}}{\emph{\DUrole{n}{r}}, \emph{\DUrole{n}{t}}, \emph{\DUrole{n}{w}}, \emph{\DUrole{n}{minS}}, \emph{\DUrole{n}{maxS}}, \emph{\DUrole{n}{step}}}{}
\sphinxAtStartPar
Segmentation manager for interfacing with Segmenter class

\sphinxAtStartPar
Find segments of a reference dataset in a target dataset using
a rolling correlation of \sphinxstyleemphasis{n} number of reference examples with
a peak detection applied to the average of \sphinxstyleemphasis{m} reference features
with weights applied to each feature.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{r}}] \leavevmode{[}List{[}Dict{[}key,numpy.array{]}{]}{]}
\sphinxAtStartPar
reference data of form
\sphinxcode{\sphinxupquote{{[} \{(feature Key): {[}data array{]} \}, \{(feature Key): {[}data array{]} \} {]}}}

\item[{\sphinxstylestrong{t}}] \leavevmode{[}Dict{[}key,numpy.array{]}{]}
\sphinxAtStartPar
target data of form
\sphinxcode{\sphinxupquote{\{ (feature Key): {[}data array{]} \}}}

\item[{\sphinxstylestrong{w}}] \leavevmode{[}Dict{[}key,float{]} or None{]}
\sphinxAtStartPar
Weights of form
\sphinxcode{\sphinxupquote{\{ (feature key):float,(feature key):float \}}}

\item[{\sphinxstylestrong{minS}}] \leavevmode{[}int{]}
\sphinxAtStartPar
Minimum scale to apply for reference data

\item[{\sphinxstylestrong{maxS}}] \leavevmode{[}int{]}
\sphinxAtStartPar
Maximum scale to apply for reference data

\item[{\sphinxstylestrong{step}}] \leavevmode{[}int{]}
\sphinxAtStartPar
Size of step to use in rolling correlation

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxstyleemphasis{3 x n} array}] \leavevmode
\sphinxAtStartPar
segments of form
\sphinxcode{\sphinxupquote{{[}start of segment,end of segment,correlation score{]}}}

\end{description}

\end{description}\end{quote}
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\end{sphinxVerbatim}

\sphinxAtStartPar
First we import sample data from the examples folder that has multiple
features derived from motion capture data

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{r}\PYG{p}{,}\PYG{n}{t}\PYG{p}{,}\PYG{n}{w} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{sampleData}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Then we define some segmentation parameters such as the scaling percentage
of the reference data and index stepping to use in rolling correlation

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{minW} \PYG{o}{=} \PYG{l+m+mi}{70} \PYG{c+c1}{\PYGZsh{} percent to scale down reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{maxW} \PYG{o}{=} \PYG{l+m+mi}{150} \PYG{c+c1}{\PYGZsh{} percent to scale up reference data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{step} \PYG{o}{=} \PYG{l+m+mi}{1} \PYG{c+c1}{\PYGZsh{}step to use for correlating reference to target data}
\end{sphinxVerbatim}

\sphinxAtStartPar
Finally we call the segmentation algorithm

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{segment\PYGZus{}data}\PYG{p}{(}\PYG{n}{r}\PYG{p}{,}\PYG{n}{t}\PYG{p}{,}\PYG{n}{w}\PYG{p}{,}\PYG{n}{minW}\PYG{p}{,}\PYG{n}{maxW}\PYG{p}{,}\PYG{n}{step}\PYG{p}{)}\PYG{p}{,}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{g+go}{array([[207.       , 240.       ,   0.9124224],}
\PYG{g+go}{       [342.       , 381.       ,   0.8801901],}
\PYG{g+go}{       [ 72.       , 112.       ,   0.8776795]])}
\end{sphinxVerbatim}

\end{fulllineitems}



\subsection{Class}
\label{\detokenize{code:class}}
\sphinxAtStartPar
The Class reference should be used for any advanced usage or when needing
convenience functions for adding data and tuning parameters of the segmentation process.


\subsubsection{Segmenter Class}
\label{\detokenize{segmenter:segmenter-class}}\label{\detokenize{segmenter::doc}}

\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.Segmenter:seg1d.Segmenter}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{Segmenter}}}}}
&
\sphinxAtStartPar
Segmentation class that exposes all algorithm parameters and attributes for advanced access and tuning of segmentation.
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}


\paragraph{seg1d.Segmenter}
\label{\detokenize{generated/seg1d.Segmenter:seg1d-segmenter}}\label{\detokenize{generated/seg1d.Segmenter::doc}}\index{Segmenter (class in seg1d)@\spxentry{Segmenter}\spxextra{class in seg1d}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.Segmenter:seg1d.Segmenter}}\pysigline{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{seg1d.}}\sphinxbfcode{\sphinxupquote{Segmenter}}}
\sphinxAtStartPar
Segmentation class that exposes all algorithm parameters and attributes for
advanced access and tuning of segmentation.

\sphinxAtStartPar
Additional convenience methods for adding reference and target data as
numpy arrays are provided.

\sphinxAtStartPar
Results of each step of the algorithm process can be accessed through the
class Attributes after running the segmentation. These can likewise be
passed to the algorithms methods described in the documentation.
\subsubsection*{Examples}

\sphinxAtStartPar
Simple usage of the class by directly assigning attributes
using sample data included with this package.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}Make an instance of the segmenter}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{Segmenter}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}retrieve the sample reference, target, and weight data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{r}\PYG{p}{,}\PYG{n}{s}\PYG{o}{.}\PYG{n}{t}\PYG{p}{,}\PYG{n}{s}\PYG{o}{.}\PYG{n}{w} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{sampleData}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}set the parameters}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{minW}\PYG{p}{,}\PYG{n}{s}\PYG{o}{.}\PYG{n}{maxW}\PYG{p}{,}\PYG{n}{s}\PYG{o}{.}\PYG{n}{step} \PYG{o}{=} \PYG{l+m+mi}{70}\PYG{p}{,} \PYG{l+m+mi}{150}\PYG{p}{,} \PYG{l+m+mi}{1}
\PYG{g+go}{\PYGZgt{}\PYGZgt{}\PYGZgt{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{s}\PYG{o}{.}\PYG{n}{segment}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{g+go}{array([[207.       , 240.       ,   0.9124224],}
\PYG{g+go}{       [342.       , 381.       ,   0.8801901],}
\PYG{g+go}{       [ 72.       , 112.       ,   0.8776795]])}
\end{sphinxVerbatim}
\index{\_\_init\_\_() (seg1d.Segmenter method)@\spxentry{\_\_init\_\_()}\spxextra{seg1d.Segmenter method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.Segmenter:seg1d.Segmenter.__init__}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{}{}
\sphinxAtStartPar
Initialization of segmentation class and parameters
\begin{quote}\begin{description}
\item[{Attributes}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{r}}] \leavevmode{[}array of dicts{]}
\sphinxAtStartPar
The reference dataset

\item[{\sphinxstylestrong{t}}] \leavevmode{[}dict{]}
\sphinxAtStartPar
The target dataset

\item[{\sphinxstylestrong{w}}] \leavevmode{[}dict{]}
\sphinxAtStartPar
Weights for correlation

\item[{\sphinxstylestrong{minW}}] \leavevmode{[}int{]}
\sphinxAtStartPar
minimum percent to scale data

\item[{\sphinxstylestrong{maxW}}] \leavevmode{[}int{]}
\sphinxAtStartPar
maximum percent to scale data

\item[{\sphinxstylestrong{step}}] \leavevmode{[}int{]}
\sphinxAtStartPar
step size for rolling correlation

\item[{\sphinxstylestrong{wSizes}}] \leavevmode{[}list{]}
\sphinxAtStartPar
sizes to use for resampling reference
(can be used instead of minW,maxW,step)

\item[{\sphinxstylestrong{cMax}}] \leavevmode{[}bool{]}
\sphinxAtStartPar
use maximum in rolling correlation (default False)

\item[{\sphinxstylestrong{cMin}}] \leavevmode{[}float{]}
\sphinxAtStartPar
\sphinxhyphen{}1 to 1, min correlation

\item[{\sphinxstylestrong{cAdd}}] \leavevmode{[}float{]}
\sphinxAtStartPar
0 to 1 or None, value to add for forcing clusters (Default 0.5)

\item[{\sphinxstylestrong{pD}}] \leavevmode{[}None{]}
\sphinxAtStartPar
peak distance to use for scipy peak detection (Default None)

\item[{\sphinxstylestrong{nC}}] \leavevmode{[}int{]}
\sphinxAtStartPar
number of clusters for correlation results

\item[{\sphinxstylestrong{fMode}}] \leavevmode{[}\{w, m, s\}{]}
\sphinxAtStartPar
keyword to use for aggregating feature correlations (default \sphinxstyleemphasis{w}).
Options, w=weighted mean, m=mean, s=sum

\item[{\sphinxstylestrong{fScale}}] \leavevmode{[}bool{]}
\sphinxAtStartPar
scale the feature correlation by its weight before feature
aggregation (Default True)

\item[{\sphinxstylestrong{tSeg}}] \leavevmode{[}{[}{]}{]}
\sphinxAtStartPar
the target data as segmented arrays

\end{description}

\end{description}\end{quote}

\end{fulllineitems}

\subsubsection*{Methods}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.Segmenter:seg1d.Segmenter.__init__}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{\_\_init\_\_}}}}}()
&
\sphinxAtStartPar
Initialization of segmentation class and parameters
\\
\hline
\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.Segmenter.add_reference:seg1d.Segmenter.add_reference}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{add\_reference}}}}}(r{[}, copy{]})
&
\sphinxAtStartPar
Appends a reference containing one or more features to the existing reference dataset.
\\
\hline
\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.Segmenter.clear_reference:seg1d.Segmenter.clear_reference}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{clear\_reference}}}}}()
&
\sphinxAtStartPar
Removes any reference data currently assigned
\\
\hline
\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.Segmenter.segment:seg1d.Segmenter.segment}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{segment}}}}}()
&
\sphinxAtStartPar
Method to run the segmentation algorithm on the current Segmenter instance
\\
\hline
\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.Segmenter.set_target:seg1d.Segmenter.set_target}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{set\_target}}}}}(t{[}, copy{]})
&
\sphinxAtStartPar
Sets the target data by overiding any existing target.
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}
\subsubsection*{Attributes}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{clusters}}
&
\sphinxAtStartPar
Segments reduced by clustering algorithm from {\hyperref[\detokenize{generated/seg1d.algorithm.cluster:seg1d.algorithm.cluster}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{algorithm.cluster()}}}}}
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{combined}}
&
\sphinxAtStartPar
The averaged correlation of the rolling feature correlation and the weighting table created by {\hyperref[\detokenize{generated/seg1d.algorithm.combine_corr:seg1d.algorithm.combine_corr}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{algorithm.combine\_corr()}}}}}
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{corrs}}
&
\sphinxAtStartPar
Rolling correlation of reference and target features created by {\hyperref[\detokenize{generated/seg1d.algorithm.rolling_corr:seg1d.algorithm.rolling_corr}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{algorithm.rolling\_corr()}}}}}
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{groups}}
&
\sphinxAtStartPar
Possible segments through parsing overlapping segment locations defined by {\hyperref[\detokenize{generated/seg1d.algorithm.uniques:seg1d.algorithm.uniques}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{algorithm.uniques()}}}}}
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{peaks}}
&
\sphinxAtStartPar
Peaks of the correlations created by {\hyperref[\detokenize{generated/seg1d.algorithm.get_peaks:seg1d.algorithm.get_peaks}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{algorithm.get\_peaks()}}}}}
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{t\_masked}}
&
\sphinxAtStartPar
The target data as ndarray masked with the non\sphinxhyphen{}defined segments as NaNs.
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{t\_segments}}
&
\sphinxAtStartPar
Returns an array of segmented target data
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}

\end{fulllineitems}



\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

\end{longtable}\sphinxatlongtableend\end{savenotes}


\subsubsection{Segmenter Methods}
\label{\detokenize{segmenter_meth:segmenter-methods}}\label{\detokenize{segmenter_meth::doc}}
\sphinxAtStartPar
These methods are used to handle data and run the segmentation process.


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.Segmenter.set_target:seg1d.Segmenter.set_target}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{set\_target}}}}}(t{[}, copy{]})
&
\sphinxAtStartPar
Sets the target data by overiding any existing target.
\\
\hline
\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.Segmenter.add_reference:seg1d.Segmenter.add_reference}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{add\_reference}}}}}(r{[}, copy{]})
&
\sphinxAtStartPar
Appends a reference containing one or more features to the existing reference dataset.
\\
\hline
\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.Segmenter.clear_reference:seg1d.Segmenter.clear_reference}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{clear\_reference}}}}}()
&
\sphinxAtStartPar
Removes any reference data currently assigned
\\
\hline
\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.Segmenter.segment:seg1d.Segmenter.segment}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{segment}}}}}()
&
\sphinxAtStartPar
Method to run the segmentation algorithm on the current Segmenter instance
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}


\paragraph{seg1d.Segmenter.set\_target}
\label{\detokenize{generated/seg1d.Segmenter.set_target:seg1d-segmenter-set-target}}\label{\detokenize{generated/seg1d.Segmenter.set_target::doc}}\index{set\_target() (seg1d.Segmenter method)@\spxentry{set\_target()}\spxextra{seg1d.Segmenter method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.Segmenter.set_target:seg1d.Segmenter.set_target}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{Segmenter.}}\sphinxbfcode{\sphinxupquote{set\_target}}}{\emph{\DUrole{n}{t}}, \emph{\DUrole{n}{copy}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
\sphinxAtStartPar
Sets the target data by overiding any existing target.
If the target is not a dict, it will be converted to one.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{t}}] \leavevmode{[}dict or ndarray{]}
\begin{DUlineblock}{0em}
\item[] Dictionary containing labeled features as keys and values as 1\sphinxhyphen{}D
arrays (must be same size).
\item[] ndarray of dimension 1 will be used as a single feature
for the target.
\item[] ndarray of n\sphinxhyphen{}dimensions will use rows as unique features.
\end{DUlineblock}

\item[{\sphinxstylestrong{copy}}] \leavevmode{[}bool, optional{]}
\sphinxAtStartPar
If True, will make a deepcopy of the passed parameter (Default True)

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{None}] \leavevmode
\end{description}

\end{description}\end{quote}


\sphinxstrong{See also:}
\nopagebreak

\begin{description}
\item[{{\hyperref[\detokenize{generated/seg1d.Segmenter.add_reference:seg1d.Segmenter.add_reference}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{add\_reference}}}}}}] \leavevmode
\sphinxAtStartPar
Add a reference item

\end{description}


\subsubsection*{Notes}

\sphinxAtStartPar
This is the recommended method for adding a feature.
You can also set the target directly through the
Attribute \sphinxstyleemphasis{t} by \sphinxcode{\sphinxupquote{\textasciigrave{}Segmenter.t =  \textasciigrave{}}}
however, this method ensures the data labels and length or stored
properly.
Setting \sphinxstyleemphasis{t} directly must be done with a dictionary.
\subsubsection*{Examples}

\sphinxAtStartPar
Target data can be set to a single numpy array.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{Segmenter}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{t} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{set\PYGZus{}target}\PYG{p}{(}\PYG{n}{t}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{t}
\PYG{g+go}{\PYGZob{}\PYGZsq{}0\PYGZsq{}: array([0.        , 0.33333333, 0.66666667, 1.        ])\PYGZcb{}}
\end{sphinxVerbatim}

\sphinxAtStartPar
Alternatively, you can pass a 2\sphinxhyphen{}dimensional array representing
multiple features.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{Segmenter}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{t} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{set\PYGZus{}target}\PYG{p}{(}\PYG{n}{t}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{t}
\PYG{g+go}{\PYGZob{}\PYGZsq{}0\PYGZsq{}: array([0. , 0.2, 0.4]), \PYGZsq{}1\PYGZsq{}: array([0.6, 0.8, 1. ])\PYGZcb{}}
\end{sphinxVerbatim}

\end{fulllineitems}



\paragraph{seg1d.Segmenter.add\_reference}
\label{\detokenize{generated/seg1d.Segmenter.add_reference:seg1d-segmenter-add-reference}}\label{\detokenize{generated/seg1d.Segmenter.add_reference::doc}}\index{add\_reference() (seg1d.Segmenter method)@\spxentry{add\_reference()}\spxextra{seg1d.Segmenter method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.Segmenter.add_reference:seg1d.Segmenter.add_reference}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{Segmenter.}}\sphinxbfcode{\sphinxupquote{add\_reference}}}{\emph{\DUrole{n}{r}}, \emph{\DUrole{n}{copy}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
\sphinxAtStartPar
Appends a reference containing one or more features to the existing
reference dataset.
If the reference is not a dict, it will be converted to one.
If this should be the only reference set, use \sphinxcode{\sphinxupquote{clear\_reference()}}
before calling this method.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{r}}] \leavevmode{[}dict or ndarray{]}
\begin{DUlineblock}{0em}
\item[] Dictionary containing labeled features as keys and values as
1\sphinxhyphen{}D arrays (must be same size).
\item[] ndarray of dimension 1 will be used as a single feature for the
reference.
\item[] ndarray of n\sphinxhyphen{}dimensions will use rows as unique features.
\end{DUlineblock}

\item[{\sphinxstylestrong{copy}}] \leavevmode{[}bool, optional{]}
\sphinxAtStartPar
If True, will make a deepcopy of the passed parameter
(Default True).

\end{description}

\end{description}\end{quote}


\sphinxstrong{See also:}
\nopagebreak

\begin{description}
\item[{{\hyperref[\detokenize{generated/seg1d.Segmenter.set_target:seg1d.Segmenter.set_target}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{set\_target}}}}}}] \leavevmode
\sphinxAtStartPar
Set the target data

\item[{{\hyperref[\detokenize{generated/seg1d.Segmenter.clear_reference:seg1d.Segmenter.clear_reference}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{clear\_reference}}}}}}] \leavevmode
\sphinxAtStartPar
Clear the current reference data

\end{description}


\subsubsection*{Notes}

\sphinxAtStartPar
This method allows features that are not in previous references to be
added, and vice\sphinxhyphen{}versa.
It will also allow different sizes of reference data to be added.
This is done as you can explicitly declare which features to use when
segmenting.
\subsubsection*{Examples}

\sphinxAtStartPar
Add a reference with multiple features

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{Segmenter}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{r} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{add\PYGZus{}reference}\PYG{p}{(} \PYG{n}{r} \PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{r}
\PYG{g+go}{[\PYGZob{}\PYGZsq{}0\PYGZsq{}: array([0. , 0.2, 0.4]), \PYGZsq{}1\PYGZsq{}: array([0.6, 0.8, 1. ])\PYGZcb{}]}
\end{sphinxVerbatim}

\sphinxAtStartPar
Alternatively, each row of the array can be added as the same labeled
feature for different references by calling this method in a loop.
Notice this is now an array of dictionaries containing the same
feature label.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{Segmenter}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{r} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{\PYGZus{}r} \PYG{o+ow}{in} \PYG{n}{r}\PYG{p}{:} \PYG{n}{s}\PYG{o}{.}\PYG{n}{add\PYGZus{}reference}\PYG{p}{(}\PYG{n}{\PYGZus{}r}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{r}
\PYG{g+go}{[\PYGZob{}\PYGZsq{}0\PYGZsq{}: array([0. , 0.2, 0.4])\PYGZcb{}, \PYGZob{}\PYGZsq{}0\PYGZsq{}: array([0.6, 0.8, 1. ])\PYGZcb{}]}
\end{sphinxVerbatim}

\end{fulllineitems}



\paragraph{seg1d.Segmenter.clear\_reference}
\label{\detokenize{generated/seg1d.Segmenter.clear_reference:seg1d-segmenter-clear-reference}}\label{\detokenize{generated/seg1d.Segmenter.clear_reference::doc}}\index{clear\_reference() (seg1d.Segmenter method)@\spxentry{clear\_reference()}\spxextra{seg1d.Segmenter method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.Segmenter.clear_reference:seg1d.Segmenter.clear_reference}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{Segmenter.}}\sphinxbfcode{\sphinxupquote{clear\_reference}}}{}{}
\sphinxAtStartPar
Removes any reference data currently assigned
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{None}}] \leavevmode
\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{None}] \leavevmode
\end{description}

\end{description}\end{quote}


\sphinxstrong{See also:}
\nopagebreak

\begin{description}
\item[{{\hyperref[\detokenize{generated/seg1d.Segmenter.add_reference:seg1d.Segmenter.add_reference}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{add\_reference}}}}}}] \leavevmode
\sphinxAtStartPar
Add a reference item

\end{description}


\subsubsection*{Notes}

\sphinxAtStartPar
This method also clears the \sphinxstyleemphasis{rF}, and \sphinxstyleemphasis{rLen} attributes.
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}
\PYG{g+go}{\PYGZgt{}\PYGZgt{}\PYGZgt{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{Segmenter}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{add\PYGZus{}reference}\PYG{p}{(} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)} \PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{r}
\PYG{g+go}{[\PYGZob{}\PYGZsq{}0\PYGZsq{}: array([0. , 1.5, 3. ])\PYGZcb{}]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{clear\PYGZus{}reference}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{r}
\PYG{g+go}{[]}
\end{sphinxVerbatim}

\end{fulllineitems}



\paragraph{seg1d.Segmenter.segment}
\label{\detokenize{generated/seg1d.Segmenter.segment:seg1d-segmenter-segment}}\label{\detokenize{generated/seg1d.Segmenter.segment::doc}}\index{segment() (seg1d.Segmenter method)@\spxentry{segment()}\spxextra{seg1d.Segmenter method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.Segmenter.segment:seg1d.Segmenter.segment}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{Segmenter.}}\sphinxbfcode{\sphinxupquote{segment}}}{}{}
\sphinxAtStartPar
Method to run the segmentation algorithm on the current
Segmenter instance
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{None}}] \leavevmode
\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{\sphinxstyleemphasis{3 x n} array}] \leavevmode
\sphinxAtStartPar
segments of form
\sphinxcode{\sphinxupquote{{[}start of segment,end of segment,correlation score{]}}}

\end{description}

\end{description}\end{quote}
\subsubsection*{Examples}

\sphinxAtStartPar
This example is the same as the main \sphinxcode{\sphinxupquote{Segmenter}} class as it is the
interface method.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}
\PYG{g+go}{\PYGZgt{}\PYGZgt{}\PYGZgt{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}Make an instance of the segmenter}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{Segmenter}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}retrieve the sample reference, target, and weight data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{r}\PYG{p}{,}\PYG{n}{s}\PYG{o}{.}\PYG{n}{t}\PYG{p}{,}\PYG{n}{s}\PYG{o}{.}\PYG{n}{w} \PYG{o}{=} \PYG{n}{seg1d}\PYG{o}{.}\PYG{n}{sampleData}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}set the parameters}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{s}\PYG{o}{.}\PYG{n}{minW}\PYG{p}{,}\PYG{n}{s}\PYG{o}{.}\PYG{n}{maxW}\PYG{p}{,}\PYG{n}{s}\PYG{o}{.}\PYG{n}{step} \PYG{o}{=} \PYG{l+m+mi}{70}\PYG{p}{,} \PYG{l+m+mi}{150}\PYG{p}{,} \PYG{l+m+mi}{1}
\PYG{g+go}{\PYGZgt{}\PYGZgt{}\PYGZgt{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{s}\PYG{o}{.}\PYG{n}{segment}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{g+go}{array([[207.       , 240.       ,   0.9124224],}
\PYG{g+go}{       [342.       , 381.       ,   0.8801901],}
\PYG{g+go}{       [ 72.       , 112.       ,   0.8776795]])}
\end{sphinxVerbatim}

\end{fulllineitems}

\subsubsection*{See Also}

\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.Segmenter:seg1d.Segmenter}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{seg1d.Segmenter}}}}}


\subsubsection{Features Class}
\label{\detokenize{processing:features-class}}\label{\detokenize{processing::doc}}

\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{match\_len}}(dataset)
&
\sphinxAtStartPar
interpolate to the maximum sized data in the reference set
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{center}}(ref\_data)
&
\sphinxAtStartPar
subtract the mean of each feature from itself
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{shared}}(D1{[}, D2{]})
&
\sphinxAtStartPar
get data with only features shared amongst all sets
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{gen\_weights}}(dataset)
&
\sphinxAtStartPar
Create weight table from reference data
\\
\hline
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{meaningful}}(weights{[}, limit, top, include\_keys{]})
&
\sphinxAtStartPar
get a weight table of the most meaningful features
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}


\subsection{Methods}
\label{\detokenize{code:methods}}
\sphinxAtStartPar
The Methods reference explains the individual routines that are used in the segmentation process.
Although they are accessible directly, it is likely easier to (and recommended) to use the Class.


\subsubsection{Algorithm Methods}
\label{\detokenize{routines:algorithm-methods}}\label{\detokenize{routines::doc}}\subsubsection*{General Functions}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.algorithm.rolling_corr:seg1d.algorithm.rolling_corr}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{rolling\_corr}}}}}(x, yData, winSize{[}, cMax{]})
&
\sphinxAtStartPar
Rolling Correlation
\\
\hline
\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.algorithm.combine_corr:seg1d.algorithm.combine_corr}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{combine\_corr}}}}}(x, w{[}, method, scale{]})
&
\sphinxAtStartPar
Combines Weighted Correlation
\\
\hline
\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.algorithm.uniques:seg1d.algorithm.uniques}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{uniques}}}}}(sortedPeaks, srcLen)
&
\sphinxAtStartPar
Unique Segment Identification
\\
\hline
\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.algorithm.get_peaks:seg1d.algorithm.get_peaks}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{get\_peaks}}}}}(x{[}, minC, dst{]})
&
\sphinxAtStartPar
Peak Detection
\\
\hline
\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.algorithm.cluster:seg1d.algorithm.cluster}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{cluster}}}}}(segGroups{[}, segAdder, nClust{]})
&
\sphinxAtStartPar
Clustering
\\
\hline
\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.algorithm.resample:seg1d.algorithm.resample}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{resample}}}}}(x, s)
&
\sphinxAtStartPar
Interpolation
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}


\paragraph{seg1d.algorithm.rolling\_corr}
\label{\detokenize{generated/seg1d.algorithm.rolling_corr:seg1d-algorithm-rolling-corr}}\label{\detokenize{generated/seg1d.algorithm.rolling_corr::doc}}\index{rolling\_corr() (in module seg1d.algorithm)@\spxentry{rolling\_corr()}\spxextra{in module seg1d.algorithm}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.algorithm.rolling_corr:seg1d.algorithm.rolling_corr}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{seg1d.algorithm.}}\sphinxbfcode{\sphinxupquote{rolling\_corr}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{yData}}, \emph{\DUrole{n}{winSize}}, \emph{\DUrole{n}{cMax}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
Rolling Correlation

\sphinxAtStartPar
Calculates the rolling correlation coefficient over the given window sizes
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{x}}] \leavevmode{[}1\sphinxhyphen{}D array{]}
\sphinxAtStartPar
array of target data

\item[{\sphinxstylestrong{yData}}] \leavevmode{[}2\sphinxhyphen{}D array{]}
\sphinxAtStartPar
array of reference data

\item[{\sphinxstylestrong{winSize}}] \leavevmode{[}int{]}
\sphinxAtStartPar
scale of the that the reference data should be rescaled to

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{ndarray}] \leavevmode
\sphinxAtStartPar
1\sphinxhyphen{}D array of length (size(x) \sphinxhyphen{} winSize + 1)

\end{description}

\item[{Other Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{cMax}}] \leavevmode{[}bool, optional{]}
\sphinxAtStartPar
Use maximum of correlations (Default False)

\end{description}

\end{description}\end{quote}

\begin{sphinxadmonition}{warning}{Warning:}
\begin{DUlineblock}{0em}
\item[] The reference data (yData) must be smaller than the target data (x)
AFTER resampling.
\item[] This means if the reference data is length 80, and the target data is
length 100, it will work. However, if the winSize is supposed to be length
120, the reference will be scaled and correlation will crash.
\end{DUlineblock}
\end{sphinxadmonition}


\sphinxstrong{See also:}
\nopagebreak

\begin{description}
\item[{{\hyperref[\detokenize{generated/seg1d.algorithm.combine_corr:seg1d.algorithm.combine_corr}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{combine\_corr}}}}}}] \leavevmode
\sphinxAtStartPar
(takes the return of this function)

\end{description}


\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}\PYG{n+nn}{.}\PYG{n+nn}{algorithm} \PYG{k}{as} \PYG{n+nn}{alg}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}make waves}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sin}\PYG{p}{(} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{)} \PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{y} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sin}\PYG{p}{(} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{80}\PYG{p}{)} \PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{l+m+mi}{20}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}apply rolling correlations with 10 and 15}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{alg}\PYG{o}{.}\PYG{n}{rolling\PYGZus{}corr}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{,} \PYG{l+m+mi}{10} \PYG{p}{)}
\PYG{g+go}{array([\PYGZhy{}0.00766151,  0.02078156,  0.03501678,  0.04019572,  0.04211895,}
\PYG{g+go}{        0.04262637,  0.04211895,  0.04019572,  0.03501678,  0.02078156,}
\PYG{g+go}{       \PYGZhy{}0.00766151])}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{alg}\PYG{o}{.}\PYG{n}{rolling\PYGZus{}corr}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{,} \PYG{l+m+mi}{15} \PYG{p}{)}
\PYG{g+go}{array([0.03321832, 0.03972237, 0.04254858, 0.04254858, 0.03972237,}
\PYG{g+go}{       0.03321832])}
\end{sphinxVerbatim}

\end{fulllineitems}



\paragraph{seg1d.algorithm.combine\_corr}
\label{\detokenize{generated/seg1d.algorithm.combine_corr:seg1d-algorithm-combine-corr}}\label{\detokenize{generated/seg1d.algorithm.combine_corr::doc}}\index{combine\_corr() (in module seg1d.algorithm)@\spxentry{combine\_corr()}\spxextra{in module seg1d.algorithm}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.algorithm.combine_corr:seg1d.algorithm.combine_corr}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{seg1d.algorithm.}}\sphinxbfcode{\sphinxupquote{combine\_corr}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{w}}, \emph{\DUrole{n}{method}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}m\textquotesingle{}}}, \emph{\DUrole{n}{scale}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
\sphinxAtStartPar
Combines Weighted Correlation

\sphinxAtStartPar
Takes in the correlated data results and multiply the weighting values
to each array of data for that feature.
| Combines the results of the weighted features
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{x}}] \leavevmode{[}Dict{[}int,Dict{[}string,numpy.array{]}{]}{]}
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\{scale:\{ feature: array({[}correlations{]}) \} \}}}

\item[{\sphinxstylestrong{w}}] \leavevmode{[}Dict{[}string,float{]}{]}
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\{ feature: weight \}}}

\item[{\sphinxstylestrong{method}}] \leavevmode{[}\{m,w, s\}{]}
\sphinxAtStartPar
keyword to use for aggregating feature correlations (default \sphinxstyleemphasis{m}).
Options, m=mean, w=weighted mean, s=sum

\item[{\sphinxstylestrong{scale}}] \leavevmode{[}bool, optional{]}
\sphinxAtStartPar
keyword argument for scaling the correlated feature before applying
any of the aggregation methods

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{Dict{[}int,numpy.array{]}}] \leavevmode
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\{scale: array({[}weighted correlations{]}) \}}}

\end{description}

\end{description}\end{quote}


\sphinxstrong{See also:}
\nopagebreak

\begin{description}
\item[{{\hyperref[\detokenize{generated/seg1d.algorithm.rolling_corr:seg1d.algorithm.rolling_corr}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{rolling\_corr}}}}}}] \leavevmode
\sphinxAtStartPar
(input for this function)

\item[{{\hyperref[\detokenize{generated/seg1d.algorithm.get_peaks:seg1d.algorithm.get_peaks}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{get\_peaks}}}}}}] \leavevmode
\sphinxAtStartPar
(takes the return of this function)

\end{description}


\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{random}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}\PYG{n+nn}{.}\PYG{n+nn}{algorithm} \PYG{k}{as} \PYG{n+nn}{alg}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{}make a convenience function to get a wave for sample data}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{def} \PYG{n+nf}{s}\PYG{p}{(}\PYG{n}{f1}\PYG{p}{,} \PYG{n}{f2}\PYG{p}{,} \PYG{n}{f3}\PYG{p}{)}\PYG{p}{:} \PYG{k}{return} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sin}\PYG{p}{(} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{n}{f1}\PYG{p}{,} \PYG{n}{f2}\PYG{p}{,} \PYG{n}{f3}\PYG{p}{)} \PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{p}{\PYGZob{}}
\PYG{g+gp}{... }    \PYG{l+m+mi}{10}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{a}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{s}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mf}{0.8}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{b}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{s}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mf}{0.8}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
\PYG{g+gp}{... }    \PYG{l+m+mi}{20}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{a}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{s}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mf}{0.7}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{b}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{s}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mf}{0.7}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{\PYGZcb{}}
\PYG{g+gp}{... }\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\sphinxAtStartPar
Assign some weights and find the averaged value

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{w} \PYG{o}{=} \PYG{p}{\PYGZob{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{a}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{b}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mf}{0.9} \PYG{p}{\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{a} \PYG{o}{=} \PYG{n}{alg}\PYG{o}{.}\PYG{n}{combine\PYGZus{}corr}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{w} \PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{k}\PYG{p}{,}\PYG{n}{v} \PYG{o+ow}{in} \PYG{n}{a}\PYG{o}{.}\PYG{n}{items}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:} \PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{k}\PYG{p}{,}\PYG{n}{v}\PYG{p}{)}
\PYG{g+go}{10 [\PYGZhy{}0.14694631 \PYGZhy{}0.07296588  0.00666771  0.0857847   0.15825538  0.21846498}
\PYG{g+go}{  0.26174865  0.28475292  0.2856955   0.26450336]}
\PYG{g+go}{20 [\PYGZhy{}0.20225425 \PYGZhy{}0.12293111 \PYGZhy{}0.03630481  0.0524783   0.13814375  0.21560229}
\PYG{g+go}{  0.2802522   0.32825274  0.35675226  0.36405765]}
\end{sphinxVerbatim}

\sphinxAtStartPar
Change the weight values and see the weighted scores change

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{w} \PYG{o}{=} \PYG{p}{\PYGZob{}} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{a}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mf}{0.9}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{b}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+m+mf}{0.2} \PYG{p}{\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{a} \PYG{o}{=} \PYG{n}{alg}\PYG{o}{.}\PYG{n}{combine\PYGZus{}corr}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{w} \PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{k}\PYG{p}{,}\PYG{n}{v} \PYG{o+ow}{in} \PYG{n}{a}\PYG{o}{.}\PYG{n}{items}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:} \PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{k}\PYG{p}{,}\PYG{n}{v}\PYG{p}{)}
\PYG{g+go}{10 [\PYGZhy{}0.26450336 \PYGZhy{}0.3270411  \PYGZhy{}0.36424081 \PYGZhy{}0.37322037 \PYGZhy{}0.35328408 \PYGZhy{}0.30597655}
\PYG{g+go}{ \PYGZhy{}0.23496298 \PYGZhy{}0.14574528 \PYGZhy{}0.04523573  0.05877853]}
\PYG{g+go}{20 [\PYGZhy{}0.36405765 \PYGZhy{}0.39304054 \PYGZhy{}0.39867347 \PYGZhy{}0.38062179 \PYGZhy{}0.33995792 \PYGZhy{}0.27909765}
\PYG{g+go}{ \PYGZhy{}0.20165658 \PYGZhy{}0.1122354  \PYGZhy{}0.01614647  0.0809017 ]}
\end{sphinxVerbatim}

\end{fulllineitems}



\paragraph{seg1d.algorithm.uniques}
\label{\detokenize{generated/seg1d.algorithm.uniques:seg1d-algorithm-uniques}}\label{\detokenize{generated/seg1d.algorithm.uniques::doc}}\index{uniques() (in module seg1d.algorithm)@\spxentry{uniques()}\spxextra{in module seg1d.algorithm}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.algorithm.uniques:seg1d.algorithm.uniques}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{seg1d.algorithm.}}\sphinxbfcode{\sphinxupquote{uniques}}}{\emph{\DUrole{n}{sortedPeaks}}, \emph{\DUrole{n}{srcLen}}}{}
\sphinxAtStartPar
Unique Segment Identification

\begin{DUlineblock}{0em}
\item[] Find unique segment(s) in a sequence of correlation values. 
\item[] Guarantees segments are not overlapping
\end{DUlineblock}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{sortedPeaks}}] \leavevmode{[}n x 3 array{]}
\sphinxAtStartPar
n x 3 array sorted by highest to lowest correlation
of form \sphinxcode{\sphinxupquote{{[} scale (int), correlation(float) , peak index (int) {]}}}

\item[{\sphinxstylestrong{srcLen}}] \leavevmode{[}int{]}
\sphinxAtStartPar
length of the target data, used to block out possible segments

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{n x 3 array}] \leavevmode
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{{[} start index, end index, correlation {]}}}

\item[{None}] \leavevmode
\sphinxAtStartPar
if no segments are found

\end{description}

\end{description}\end{quote}


\sphinxstrong{See also:}
\nopagebreak

\begin{description}
\item[{{\hyperref[\detokenize{generated/seg1d.algorithm.get_peaks:seg1d.algorithm.get_peaks}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{get\_peaks}}}}}}] \leavevmode
\sphinxAtStartPar
(input for this function)

\item[{{\hyperref[\detokenize{generated/seg1d.algorithm.cluster:seg1d.algorithm.cluster}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{cluster}}}}}}] \leavevmode
\sphinxAtStartPar
(takes in the return of this function)

\end{description}


\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}\PYG{n+nn}{.}\PYG{n+nn}{algorithm} \PYG{k}{as} \PYG{n+nn}{alg}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{p} \PYG{o}{=} \PYG{p}{[} \PYG{p}{[}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mf}{0.90}\PYG{p}{,} \PYG{l+m+mi}{7}  \PYG{p}{]}\PYG{p}{,}
\PYG{g+gp}{... }    \PYG{p}{[}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mf}{0.89}\PYG{p}{,} \PYG{l+m+mi}{8}  \PYG{p}{]}\PYG{p}{,}
\PYG{g+gp}{... }    \PYG{p}{[}\PYG{l+m+mi}{20}\PYG{p}{,} \PYG{l+m+mf}{0.80}\PYG{p}{,} \PYG{l+m+mi}{20} \PYG{p}{]}\PYG{p}{,}
\PYG{g+gp}{... }    \PYG{p}{[}\PYG{l+m+mi}{25}\PYG{p}{,} \PYG{l+m+mf}{0.70}\PYG{p}{,} \PYG{l+m+mi}{40} \PYG{p}{]}\PYG{p}{,}
\PYG{g+gp}{... }    \PYG{p}{]}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{el} \PYG{o}{=} \PYG{l+m+mi}{50}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{alg}\PYG{o}{.}\PYG{n}{uniques}\PYG{p}{(}\PYG{n}{p}\PYG{p}{,}\PYG{n}{el}\PYG{p}{)}
\PYG{g+go}{[[7, 17, 0.9], [20, 40, 0.8], [40, 65, 0.7]]}
\end{sphinxVerbatim}

\end{fulllineitems}



\paragraph{seg1d.algorithm.get\_peaks}
\label{\detokenize{generated/seg1d.algorithm.get_peaks:seg1d-algorithm-get-peaks}}\label{\detokenize{generated/seg1d.algorithm.get_peaks::doc}}\index{get\_peaks() (in module seg1d.algorithm)@\spxentry{get\_peaks()}\spxextra{in module seg1d.algorithm}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.algorithm.get_peaks:seg1d.algorithm.get_peaks}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{seg1d.algorithm.}}\sphinxbfcode{\sphinxupquote{get\_peaks}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{minC}\DUrole{o}{=}\DUrole{default_value}{0.7}}, \emph{\DUrole{n}{dst}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Peak Detection

\sphinxAtStartPar
Find the peaks of a data array with a minimum value of a peak
and an optional distance parameter.

\sphinxAtStartPar
Relies on \sphinxcode{\sphinxupquote{scipy.signal.find\_peaks}}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{x}}] \leavevmode{[}Dict{[}int,List{[}float{]}{]}{]}
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{\{scale:  {[}correlations{]} \}}}

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{n x 3 array}] \leavevmode
\sphinxAtStartPar
sorted by highest to lowest correlation of form
\sphinxcode{\sphinxupquote{{[} scale, correlation , peak index {]}}}

\end{description}

\item[{Other Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{minC}}] \leavevmode{[}float, optional{]}
\sphinxAtStartPar
\sphinxhyphen{}1 to 1

\item[{\sphinxstylestrong{dst}}] \leavevmode{[}real, optional{]}
\sphinxAtStartPar
int or float

\end{description}

\end{description}\end{quote}


\sphinxstrong{See also:}
\nopagebreak

\begin{description}
\item[{{\hyperref[\detokenize{generated/seg1d.algorithm.combine_corr:seg1d.algorithm.combine_corr}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{combine\_corr}}}}}}] \leavevmode
\sphinxAtStartPar
(input for this function)

\item[{{\hyperref[\detokenize{generated/seg1d.algorithm.uniques:seg1d.algorithm.uniques}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{uniques}}}}}}] \leavevmode
\sphinxAtStartPar
(takes the return of this function)

\end{description}


\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}\PYG{n+nn}{.}\PYG{n+nn}{algorithm} \PYG{k}{as} \PYG{n+nn}{alg}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{c+c1}{\PYGZsh{} convenience function for generating wave}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{def} \PYG{n+nf}{s}\PYG{p}{(}\PYG{n}{f1}\PYG{p}{,} \PYG{n}{f2}\PYG{p}{,} \PYG{n}{f3}\PYG{p}{)}\PYG{p}{:} \PYG{k}{return} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sin}\PYG{p}{(} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{n}{f1}\PYG{p}{,} \PYG{n}{f2}\PYG{p}{,} \PYG{n}{f3}\PYG{p}{)} \PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Define some scales that have correlations

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{p}{\PYGZob{}} \PYG{l+m+mi}{10}\PYG{p}{:} \PYG{n}{s}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{:} \PYG{n}{s}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{pi}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)} \PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

\sphinxAtStartPar
Query the peaks in the data

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{alg}\PYG{o}{.}\PYG{n}{get\PYGZus{}peaks}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{g+go}{array([[10.       ,  0.9848078,  7.       ],}
\PYG{g+go}{       [20.       ,  0.9848078,  1.       ],}
\PYG{g+go}{       [20.       ,  0.8660254,  6.       ]])}
\end{sphinxVerbatim}

\sphinxAtStartPar
Define a minimum for the peak

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{np}\PYG{o}{.}\PYG{n}{around}\PYG{p}{(}\PYG{n}{alg}\PYG{o}{.}\PYG{n}{get\PYGZus{}peaks}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{minC} \PYG{o}{=} \PYG{l+m+mf}{0.9}\PYG{p}{)}\PYG{p}{,} \PYG{n}{decimals}\PYG{o}{=}\PYG{l+m+mi}{7}\PYG{p}{)}
\PYG{g+go}{array([[10.       ,  0.9848078,  7.       ],}
\PYG{g+go}{       [20.       ,  0.9848078,  1.       ]])}
\end{sphinxVerbatim}

\end{fulllineitems}



\paragraph{seg1d.algorithm.cluster}
\label{\detokenize{generated/seg1d.algorithm.cluster:seg1d-algorithm-cluster}}\label{\detokenize{generated/seg1d.algorithm.cluster::doc}}\index{cluster() (in module seg1d.algorithm)@\spxentry{cluster()}\spxextra{in module seg1d.algorithm}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.algorithm.cluster:seg1d.algorithm.cluster}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{seg1d.algorithm.}}\sphinxbfcode{\sphinxupquote{cluster}}}{\emph{\DUrole{n}{segGroups}}, \emph{\DUrole{n}{segAdder}\DUrole{o}{=}\DUrole{default_value}{0.5}}, \emph{\DUrole{n}{nClust}\DUrole{o}{=}\DUrole{default_value}{2}}}{}
\sphinxAtStartPar
Clustering

\sphinxAtStartPar
Clusters segments based on correlation values
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{segGroups}}] \leavevmode{[}n x 3 array{]}
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{{[} {[} start index, end index, correlation {]} {]}}}

\item[{\sphinxstylestrong{segAdder}}] \leavevmode{[}float, optional{]}
\sphinxAtStartPar
0.0 to 1.0 or None
If not None, the value that is added to the cluster groups to force
a correlation cluster of the highest values

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{n x 3 array}] \leavevmode
\sphinxAtStartPar
\sphinxcode{\sphinxupquote{{[}start segment, end segment, correlation score of segment{]}}}

\end{description}

\item[{Other Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{nClust}}] \leavevmode{[}int, optional{]}
\sphinxAtStartPar
number of clusters to group data in (Default 2)

\sphinxAtStartPar
If \sphinxcode{\sphinxupquote{nClust=0}}, returns segGroups

\end{description}

\item[{Warns}] \leavevmode\begin{description}
\item[{Segment Adder value was included in final cluster.}] \leavevmode
\sphinxAtStartPar
This may mean cluster is poorly defined or Adder is too high.
It is removed before being returned. However, it may be a sign of
poor clustering settings as the intention of the segment adder is to
force clustering of highly similar segments by creating a lower group
(therefore, it should not be in the high cluster group).

\end{description}

\end{description}\end{quote}


\sphinxstrong{See also:}
\nopagebreak

\begin{description}
\item[{{\hyperref[\detokenize{generated/seg1d.algorithm.uniques:seg1d.algorithm.uniques}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{uniques}}}}}}] \leavevmode
\sphinxAtStartPar
(input for this function)

\end{description}


\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}\PYG{n+nn}{.}\PYG{n+nn}{algorithm} \PYG{k}{as} \PYG{n+nn}{alg}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{7}\PYG{p}{,} \PYG{l+m+mi}{17}\PYG{p}{,} \PYG{l+m+mf}{0.90}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{20}\PYG{p}{,} \PYG{l+m+mi}{40}\PYG{p}{,} \PYG{l+m+mf}{0.88}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{40}\PYG{p}{,} \PYG{l+m+mi}{65}\PYG{p}{,} \PYG{l+m+mf}{0.8}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{50}\PYG{p}{,} \PYG{l+m+mi}{65}\PYG{p}{,} \PYG{l+m+mf}{0.70}\PYG{p}{]}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{alg}\PYG{o}{.}\PYG{n}{cluster}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}
\PYG{g+go}{[[7, 17, 0.9], [20, 40, 0.88], [40, 65, 0.8], [50, 65, 0.7]]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{alg}\PYG{o}{.}\PYG{n}{cluster}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{segAdder}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{)}
\PYG{g+go}{[[7, 17, 0.9], [20, 40, 0.88], [40, 65, 0.8]]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{alg}\PYG{o}{.}\PYG{n}{cluster}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{segAdder}\PYG{o}{=}\PYG{l+m+mf}{0.85}\PYG{p}{)}
\PYG{g+go}{[[7, 17, 0.9], [20, 40, 0.88], [40, 65, 0.8]]}
\end{sphinxVerbatim}

\sphinxAtStartPar
Note: This should raise the following warning:
\begin{description}
\item[{UserWarning: Segment Adder value was included in final cluster.}] \leavevmode
\sphinxAtStartPar
This may mean cluster is poorly defined or Adder is too high.

\end{description}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{alg}\PYG{o}{.}\PYG{n}{cluster}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{nClust}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{)}
\PYG{g+go}{[[7, 17, 0.9], [20, 40, 0.88], [40, 65, 0.8]]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{alg}\PYG{o}{.}\PYG{n}{cluster}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{segAdder}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,}\PYG{n}{nClust}\PYG{o}{=}\PYG{l+m+mi}{3}\PYG{p}{)}
\PYG{g+go}{[[7, 17, 0.9], [20, 40, 0.88]]}
\end{sphinxVerbatim}

\end{fulllineitems}



\paragraph{seg1d.algorithm.resample}
\label{\detokenize{generated/seg1d.algorithm.resample:seg1d-algorithm-resample}}\label{\detokenize{generated/seg1d.algorithm.resample::doc}}\index{resample() (in module seg1d.algorithm)@\spxentry{resample()}\spxextra{in module seg1d.algorithm}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.algorithm.resample:seg1d.algorithm.resample}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{seg1d.algorithm.}}\sphinxbfcode{\sphinxupquote{resample}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{s}}}{}
\sphinxAtStartPar
Interpolation

\sphinxAtStartPar
Apply a cubic interpolation on an n x m dataset that is resampled
to the number of samples
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{x}}] \leavevmode{[}n x m array{]}
\sphinxAtStartPar
n\sphinxhyphen{}number of datasets with length m

\item[{\sphinxstylestrong{s}}] \leavevmode{[}int{]}
\sphinxAtStartPar
number of samples to interpolate x

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{n x s array}] \leavevmode
\sphinxAtStartPar
interpolated dataset

\end{description}

\end{description}\end{quote}


\sphinxstrong{See also:}
\nopagebreak

\begin{description}
\item[{{\hyperref[\detokenize{generated/seg1d.algorithm.cluster:seg1d.algorithm.cluster}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{cluster}}}}}}] \leavevmode
\sphinxAtStartPar
(input for this function)

\item[{{\hyperref[\detokenize{generated/seg1d.algorithm.resample:seg1d.algorithm.resample}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{resample}}}}}}] \leavevmode
\sphinxAtStartPar
(takes in the return of this function)

\end{description}


\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}\PYG{n+nn}{.}\PYG{n+nn}{algorithm} \PYG{k}{as} \PYG{n+nn}{alg}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sin}\PYG{p}{(} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)} \PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{alg}\PYG{o}{.}\PYG{n}{resample}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{)}
\PYG{g+go}{array([[\PYGZhy{}0.14112001, \PYGZhy{}0.97319156, \PYGZhy{}0.56423116,  0.56423116,  0.97319156,}
\PYG{g+go}{         0.14112001]])}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{n}{x}\PYG{p}{,}\PYG{n}{x}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{alg}\PYG{o}{.}\PYG{n}{resample}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{)}
\PYG{g+go}{array([[\PYGZhy{}0.14112001, \PYGZhy{}0.97319156, \PYGZhy{}0.56423116,  0.56423116,  0.97319156,}
\PYG{g+go}{         0.14112001],}
\PYG{g+go}{       [ 0.01991486,  0.94687756,  0.31972116,  0.31972116,  0.94687756,}
\PYG{g+go}{         0.01991486]])}
\end{sphinxVerbatim}

\end{fulllineitems}

\subsubsection*{Optimized Functions}


\begin{savenotes}\sphinxatlongtablestart\begin{longtable}[c]{\X{1}{2}\X{1}{2}}
\hline

\endfirsthead

\multicolumn{2}{c}%
{\makebox[0pt]{\sphinxtablecontinued{\tablename\ \thetable{} \textendash{} continued from previous page}}}\\
\hline

\endhead

\hline
\multicolumn{2}{r}{\makebox[0pt][r]{\sphinxtablecontinued{continues on next page}}}\\
\endfoot

\endlastfoot

\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.optimized_funcs.rcor:seg1d.optimized_funcs.rcor}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{rcor}}}}}(x, Y)
&
\sphinxAtStartPar
Correlation of multiple arrays to a single array using a rolling window correlation.
\\
\hline
\sphinxAtStartPar
{\hyperref[\detokenize{generated/seg1d.optimized_funcs.vcor:seg1d.optimized_funcs.vcor}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{vcor}}}}}(x, y)
&
\sphinxAtStartPar
Rolling correlation between two arrays.
\\
\hline
\end{longtable}\sphinxatlongtableend\end{savenotes}


\paragraph{seg1d.optimized\_funcs.rcor}
\label{\detokenize{generated/seg1d.optimized_funcs.rcor:seg1d-optimized-funcs-rcor}}\label{\detokenize{generated/seg1d.optimized_funcs.rcor::doc}}\index{rcor() (in module seg1d.optimized\_funcs)@\spxentry{rcor()}\spxextra{in module seg1d.optimized\_funcs}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.optimized_funcs.rcor:seg1d.optimized_funcs.rcor}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{seg1d.optimized\_funcs.}}\sphinxbfcode{\sphinxupquote{rcor}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{Y}}}{}
\sphinxAtStartPar
Correlation of multiple arrays to a single array using a rolling
window correlation.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{x}}] \leavevmode{[}1d array{]}
\sphinxAtStartPar
target array

\item[{\sphinxstylestrong{Y}}] \leavevmode{[}ndarray{]}
\sphinxAtStartPar
references resampled to correct size

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{n x m array}] \leavevmode
\sphinxAtStartPar
correlations of one ndarray to an m x ndarray

\end{description}

\end{description}\end{quote}
\subsubsection*{Notes}

\sphinxAtStartPar
This will try to use numba for optimization.
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}\PYG{n+nn}{.}\PYG{n+nn}{optimized\PYGZus{}funcs} \PYG{k}{as} \PYG{n+nn}{optF}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sin}\PYG{p}{(} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{25}\PYG{p}{)} \PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{y} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sin}\PYG{p}{(} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{60}\PYG{p}{)} \PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{20}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{optF}\PYG{o}{.}\PYG{n}{rcor}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{y}\PYG{p}{)}
\PYG{g+go}{array([[\PYGZhy{}0.50743663, \PYGZhy{}0.66692675, \PYGZhy{}0.78849873, \PYGZhy{}0.87803067, \PYGZhy{}0.93682968,}
\PYG{g+go}{        \PYGZhy{}0.96013818],}
\PYG{g+go}{       [ 0.83362263,  0.91097751,  0.94663428,  0.94663428,  0.91097751,}
\PYG{g+go}{         0.83362263],}
\PYG{g+go}{       [\PYGZhy{}0.96013818, \PYGZhy{}0.93682968, \PYGZhy{}0.87803067, \PYGZhy{}0.78849873, \PYGZhy{}0.66692675,}
\PYG{g+go}{        \PYGZhy{}0.50743663]])}
\end{sphinxVerbatim}

\end{fulllineitems}



\paragraph{seg1d.optimized\_funcs.vcor}
\label{\detokenize{generated/seg1d.optimized_funcs.vcor:seg1d-optimized-funcs-vcor}}\label{\detokenize{generated/seg1d.optimized_funcs.vcor::doc}}\index{vcor() (in module seg1d.optimized\_funcs)@\spxentry{vcor()}\spxextra{in module seg1d.optimized\_funcs}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{generated/seg1d.optimized_funcs.vcor:seg1d.optimized_funcs.vcor}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{seg1d.optimized\_funcs.}}\sphinxbfcode{\sphinxupquote{vcor}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{y}}}{}
\sphinxAtStartPar
Rolling correlation between two arrays.
Optimized by numba if available
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{description}
\item[{\sphinxstylestrong{x}}] \leavevmode{[}1D array{]}
\sphinxAtStartPar
array to use as static data

\item[{\sphinxstylestrong{y}}] \leavevmode{[}1D array{]}
\sphinxAtStartPar
array to use as rolling data

\end{description}

\item[{Returns}] \leavevmode\begin{description}
\item[{1D array}] \leavevmode
\sphinxAtStartPar
correlations at each increment

\sphinxAtStartPar
\sphinxcode{\sphinxupquote{size = (size(x) \sphinxhyphen{} size(y)) + 1}}

\end{description}

\end{description}\end{quote}
\subsubsection*{Notes}

\sphinxAtStartPar
Required: \sphinxcode{\sphinxupquote{size(x) \textgreater{} size(y)}}
This will try to use numba for optimization.
\subsubsection*{Examples}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{seg1d}\PYG{n+nn}{.}\PYG{n+nn}{optimized\PYGZus{}funcs} \PYG{k}{as} \PYG{n+nn}{optF}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sin}\PYG{p}{(} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{25}\PYG{p}{)} \PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{y} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sin}\PYG{p}{(} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{20}\PYG{p}{)} \PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{optF}\PYG{o}{.}\PYG{n}{vcor}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{y}\PYG{p}{)}
\PYG{g+go}{array([0.83212194, 0.90933756, 0.94493014, 0.94493014, 0.90933756,}
\PYG{g+go}{       0.83212194])}
\end{sphinxVerbatim}

\end{fulllineitems}

\phantomsection\label{\detokenize{code:module-seg1d}}\index{module@\spxentry{module}!seg1d@\spxentry{seg1d}}\index{seg1d@\spxentry{seg1d}!module@\spxentry{module}}
\sphinxAtStartPar
seg1d:  Python module for automated 1D subsequence segmentation
Copyright (C) 2020  Mathew Schwartz
\phantomsection\label{\detokenize{code:module-seg1d.segment}}\index{module@\spxentry{module}!seg1d.segment@\spxentry{seg1d.segment}}\index{seg1d.segment@\spxentry{seg1d.segment}!module@\spxentry{module}}\phantomsection\label{\detokenize{code:module-segment}}\index{module@\spxentry{module}!segment@\spxentry{segment}}\index{segment@\spxentry{segment}!module@\spxentry{module}}\phantomsection\label{\detokenize{code:module-seg1d.algorithm}}\index{module@\spxentry{module}!seg1d.algorithm@\spxentry{seg1d.algorithm}}\index{seg1d.algorithm@\spxentry{seg1d.algorithm}!module@\spxentry{module}}\phantomsection\label{\detokenize{code:module-algorithm}}\index{module@\spxentry{module}!algorithm@\spxentry{algorithm}}\index{algorithm@\spxentry{algorithm}!module@\spxentry{module}}\phantomsection\label{\detokenize{code:module-seg1d.optimized_funcs}}\index{module@\spxentry{module}!seg1d.optimized\_funcs@\spxentry{seg1d.optimized\_funcs}}\index{seg1d.optimized\_funcs@\spxentry{seg1d.optimized\_funcs}!module@\spxentry{module}}\phantomsection\label{\detokenize{code:module-optimized_funcs}}\index{module@\spxentry{module}!optimized\_funcs@\spxentry{optimized\_funcs}}\index{optimized\_funcs@\spxentry{optimized\_funcs}!module@\spxentry{module}}\phantomsection\label{\detokenize{code:module-seg1d.examples}}\index{module@\spxentry{module}!seg1d.examples@\spxentry{seg1d.examples}}\index{seg1d.examples@\spxentry{seg1d.examples}!module@\spxentry{module}}

\section{Community Guidelines}
\label{\detokenize{community:community-guidelines}}\label{\detokenize{community::doc}}

\subsection{Issues}
\label{\detokenize{community:issues}}
\sphinxAtStartPar
Issues and feature requests should be submitted on \sphinxhref{https://github.com/cadop/seg1d/issues}{github} .


\subsection{Contributing}
\label{\detokenize{community:contributing}}
\sphinxAtStartPar
Please follow the fork\sphinxhyphen{}and\sphinxhyphen{}pull Git workflow.
However, it is suggested to create an issue first to confirm the contributions align with the future of the module.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Fork} the repo on GitHub

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Clone} the project to your own machine

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Commit} changes to your own branch

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Push} your work back up to your fork

\item {} 
\sphinxAtStartPar
Submit a \sphinxstylestrong{Pull request} so that we can review your changes

\end{enumerate}

\sphinxAtStartPar
Documentation is on the main branch of the repository (rather than gh\sphinxhyphen{}pages) and should be built as\sphinxhyphen{}is.
A redirect \sphinxcode{\sphinxupquote{index.html}} file handles moving the github pages to the build directory and a \sphinxcode{\sphinxupquote{.nojekyll}} file
preserves folder types.


\subsection{Copyright and Licensing}
\label{\detokenize{community:copyright-and-licensing}}
\sphinxAtStartPar
Please refer to the full \sphinxhref{https://github.com/cadop/seg1d/blob/master/LICENSE.txt}{LICENSE} text.


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{a}
\item\relax\sphinxstyleindexentry{algorithm}\sphinxstyleindexextra{Unix, Windows}\sphinxstyleindexpageref{code:\detokenize{module-algorithm}}
\indexspace
\bigletter{o}
\item\relax\sphinxstyleindexentry{optimized\_funcs}\sphinxstyleindexextra{Unix, Windows}\sphinxstyleindexpageref{code:\detokenize{module-optimized_funcs}}
\indexspace
\bigletter{s}
\item\relax\sphinxstyleindexentry{seg1d}\sphinxstyleindexpageref{code:\detokenize{module-seg1d}}
\item\relax\sphinxstyleindexentry{seg1d.algorithm}\sphinxstyleindexpageref{code:\detokenize{module-seg1d.algorithm}}
\item\relax\sphinxstyleindexentry{seg1d.examples}\sphinxstyleindexpageref{code:\detokenize{module-seg1d.examples}}
\item\relax\sphinxstyleindexentry{seg1d.examples.ex\_ecg}\sphinxstyleindexpageref{api_ecg:\detokenize{module-seg1d.examples.ex_ecg}}
\item\relax\sphinxstyleindexentry{seg1d.examples.ex\_feature\_processing}\sphinxstyleindexpageref{api_processing:\detokenize{module-seg1d.examples.ex_feature_processing}}
\item\relax\sphinxstyleindexentry{seg1d.examples.ex\_gauss}\sphinxstyleindexpageref{start:\detokenize{module-seg1d.examples.ex_gauss}}
\item\relax\sphinxstyleindexentry{seg1d.examples.ex\_segmenter\_features}\sphinxstyleindexpageref{api_feat:\detokenize{module-seg1d.examples.ex_segmenter_features}}
\item\relax\sphinxstyleindexentry{seg1d.examples.ex\_segmenter\_sine}\sphinxstyleindexpageref{api_basic:\detokenize{module-seg1d.examples.ex_segmenter_sine}}
\item\relax\sphinxstyleindexentry{seg1d.examples.ex\_simple}\sphinxstyleindexpageref{start:\detokenize{module-seg1d.examples.ex_simple}}
\item\relax\sphinxstyleindexentry{seg1d.examples.ex\_sine}\sphinxstyleindexpageref{start:\detokenize{module-seg1d.examples.ex_sine}}
\item\relax\sphinxstyleindexentry{seg1d.examples.ex\_sine\_noise}\sphinxstyleindexpageref{api_tune:\detokenize{module-seg1d.examples.ex_sine_noise}}
\item\relax\sphinxstyleindexentry{seg1d.optimized\_funcs}\sphinxstyleindexpageref{code:\detokenize{module-seg1d.optimized_funcs}}
\item\relax\sphinxstyleindexentry{seg1d.segment}\sphinxstyleindexpageref{code:\detokenize{module-seg1d.segment}}
\item\relax\sphinxstyleindexentry{segment}\sphinxstyleindexextra{Unix, Windows}\sphinxstyleindexpageref{code:\detokenize{module-segment}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}